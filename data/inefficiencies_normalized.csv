cer_id,cloud_provider,focus_category,service,title,summary,severity,status
CER-002017,azure,focus_ai,azure-cognitive-services,Always-On PTUs for Seasonal or Cyclical Azure OpenAI Workloads,"Many Azure OpenAI workloads—such as reporting pipelines, marketing workflows, batch inference jobs, or time-bound customer interactions—only run during specific periods. When PTUs remain fully provisioned 24/7, organizations incur continuous fixed cost even during extended idle time. Although Azure does not offer native PTU scheduling, teams can use automation to provision and deprovision PTUs bas",medium,published
CER-002119,azure,focus_storage,azure-blob-storage,Archival Blob Container Storing Objects in Non-Archival Tiers,"This inefficiency occurs when a blob container intended for long-term or infrequently accessed data continues to store objects in higher-cost tiers like Hot or Cool, instead of using the Archive tier. This often happens when containers are created without lifecycle policies or default tier settings. Over time, storing archival data in non-archival tiers results in avoidable cost without any perfor",medium,published
CER-008397,azure,focus_database,azure-sql,Azure Hybrid Benefit Not Enabled on SQL Databases,"Azure Hybrid Benefit allows organizations to apply existing SQL Server licenses with Software Assurance or qualifying subscriptions to Azure SQL Databases. When this configuration is missed or not enforced, workloads continue to incur license-inclusive costs despite license ownership. This oversight often occurs in environments where licensing governance is decentralized or when databases are prov",medium,published
CER-001255,azure,focus_compute,azure-virtual-machines,Azure Hybrid Benefit Not Enabled on Virtual Machines,"Many organizations purchase Software Assurance or subscription-based Windows and SQL Server licenses that entitle them to use Azure Hybrid Benefit. However, if the setting is not applied on eligible resources, Azure continues charging pay-as-you-go rates that already include Microsoft licensing costs. This oversight results in paying twice—once for the on-premises license and once for the built-in",medium,published
CER-001612,gcp,focus_other,gcp-cloud-marketplace,Billing Account Migration Creating Emergency List-Price Purchases in Google Cloud Marketplace,"Changing a Google Cloud billing account can unintentionally break existing Marketplace subscriptions. If entitlements are tied to the original billing account, the subscription may fail or become invalid, prompting teams to make urgent, direct purchases of the same services, often at higher list or on-demand rates. These emergency purchases bypass previously negotiated Marketplace pricing and can ",medium,published
CER-005008,azure,focus_database,azure-sql,Business Critical Tier on Non-Production SQL Instance,"Non-production environments such as development, testing, or staging often do not require the high availability, failover capabilities, and premium storage performance offered by the Business Critical tier. Running these workloads on Business Critical unnecessarily inflates costs. Choosing a lower-cost tier like General Purpose typically provides sufficient performance and availability for non-pro",medium,published
CER-006716,aws,focus_other,aws-config,Continuous AWS Config Recording in Non-Production Environments,"By default, AWS Config is enabled in continuous recording mode. While this may be justified for production workloads where detailed auditability is critical, it is rarely necessary in non-production environments. Frequent changes in development or testing environments — such as redeploying Lambda functions, ECS tasks, or EC2 instances — generate large volumes of CIRs. This results in disproportion",medium,published
CER-004583,aws,focus_storage,aws-s3,Delayed Transition of Objects to Intelligent-Tiering in an S3 Bucket,"Some S3 lifecycle policies are configured to transition objects from Standard storage to Intelligent-Tiering after a fixed number of days (e.g., 30 days). This creates a delay where objects reside in S3 Standard, incurring higher storage costs without benefit. Since Intelligent-Tiering does not require prior access history and can be used immediately, it is often more efficient to place objects di",medium,published
CER-001070,aws,focus_storage,aws-ebs,Delete-on-Termination Disabled for EBS Volume,"When EC2 instances are provisioned, each attached EBS volume has a `DeleteOnTermination` flag that determines whether it will be deleted when the instance is terminated. If this flag is set to `false` — often unintentionally in custom launch templates, AMIs, or older automation scripts — volumes persist after termination, resulting in orphaned storage. While detached volumes are easy to detect and",medium,published
CER-004734,aws,focus_other,aws-eventbridge,Disabled Retry Policies in EventBridge,"By default, EventBridge includes retry mechanisms for delivery failures, particularly when targets like Lambda functions or Step Functions fail to process an event. However, if these retry policies are disabled or misconfigured, EventBridge may treat failed deliveries as successful, prompting upstream services to republish the same event multiple times in response to undelivered outcomes. This lea",medium,published
CER-001883,aws,focus_other,aws-marketplace,Double Counting on EDP Commitments,"Many organizations mistakenly believe that all AWS Marketplace spend automatically contributes to their EDP commitment. In reality, only certain Marketplace transactions, those involving EDP-eligible vendors and transactable SKUs, will count towards a portion of their EDP commitment. This misunderstanding can lead to double counting: forecasting based on the assumption that both native AWS usage a",medium,published
CER-009482,gcp,focus_other,gcp-cloud-logging,Duplicate Storage of Logs in Cloud Logging,"Duplicate log storage occurs when multiple sinks capture the same log data — for example, organization-wide sinks exporting all logs to Cloud Storage and project-level sinks doing the same. This redundancy results in paying twice (or more) for identical data. It often arises from decentralized logging configurations, inherited policies, or unclear ownership between teams. The problem is compounded",medium,published
CER-008369,aws,focus_other,aws-cloudtrail,Duplicate or Overlapping AWS CloudTrail Trails,"AWS CloudTrail enables event logging across AWS services, but when multiple trails are configured to log overlapping events — especially data events — it can result in redundant charges and unnecessary storage or ingestion costs. This commonly occurs in decentralized environments where teams create trails independently, unaware of existing coverage or shared logging destinations.Each trail that re",medium,published
CER-009602,aws,focus_network,aws-elb,Elastic Load Balancer with Only One EC2 Instance,"An ELB with only one registered EC2 instance does not achieve its core purpose—distributing traffic across multiple backends. In this configuration, the ELB adds complexity and cost without improving availability, scalability, or fault tolerance. This setup is often the result of premature scaling design or misunderstood architecture patterns. If there's no plan to horizontally scale the applicati",medium,published
CER-003662,aws,focus_other,aws-config,Excessive AWS Config Costs from Spot Instances,"Spot Instances are designed to be short-lived, with frequent interruptions and replacements. When AWS Config continuously records every lifecycle change for these instances, it produces a large number of CIRs. This drives costs significantly higher without delivering meaningful compliance insight, since Spot Instances are typically stateless and non-critical. In environments with heavy Spot usage,",medium,published
CER-009045,snowflake,focus_other,snowflake-automatic-clustering-service,Excessive Auto-Clustering Costs from High-Churn Tables,"Excessive Auto-Clustering costs occur when tables experience frequent and large-scale modifications (""high churn""), causing Snowflake to constantly recluster data. This leads to significant and often hidden compute consumption for maintenance tasks, especially when table structures or loading patterns are not optimized. Poor clustering key choices, unordered data loads, or frequent full-table repl",medium,published
CER-003023,aws,focus_storage,aws-s3,Excessive CloudTrail Charges from Bulk S3 Deletes,"When large numbers of objects are deleted from S3—such as during cleanup or lifecycle transitions—CloudTrail can log every individual delete operation if data event logging is enabled. This is especially costly when deleting millions of objects from buckets configured with CloudTrail data event logging at the object level. The resulting volume of logs can cause a significant, unexpected spike in C",medium,published
CER-007159,aws,focus_other,aws-cloudwatch,Excessive CloudWatch Log Volume from Persistently Enabled Debugging,"Engineers often enable verbose logging (e.g., debug or trace-level) during development or troubleshooting, then forget to disable it after deployment. This results in elevated log ingestion rates — and therefore costs — even when the detailed logs are no longer needed. Because CloudWatch Logs charges per GB ingested, persistent debug logging in production environments can create silent but materia",medium,published
CER-007557,gcp,focus_compute,gcp-cloud-functions,Excessive Cold Starts in GCP Cloud Functions,"Cloud Functions scale to zero when idle. When invoked after inactivity, they undergo a ""cold start,"" initializing runtime, loading dependencies, and establishing any required network connections (e.g., VPC connectors). These cold starts can dramatically increase execution time, especially for functions with: * High memory allocations * Heavy initialization logic * VPC connector requirements If col",medium,published
CER-002141,gcp,focus_database,gcp-bigquery,Excessive Data Scanned Due to Unpartitioned Tables in BigQuery,"If a table is not partitioned by a relevant column (typically a timestamp), every query scans the entire dataset, even if filtering by date. This leads to: * High costs per query * Long execution times * Inefficient use of resources when querying recent or small subsets of data This inefficiency is especially common in: * Event or log data stored in raw, unpartitioned form Historical data migratio",medium,published
CER-007226,aws,focus_storage,aws-s3,Excessive KMS Charges from Missing S3 Bucket Key Configuration,"S3 buckets configured with SSE-KMS but without Bucket Keys generate a separate KMS request for each object operation. This behavior results in disproportionately high KMS request costs for data-intensive workloads such as analytics, backups, or frequently accessed objects. Bucket Keys allow S3 to cache KMS data keys at the bucket level, reducing the volume of KMS calls and cutting encryption costs",medium,published
CER-002980,aws,focus_compute,aws-lambda,Excessive Lambda Duration from Synchronous Waiting,"Some Lambda functions perform synchronous calls to other services, APIs, or internal microservices and wait for the response before proceeding. During this time, the Lambda is idle from a compute perspective but still fully billed. This anti-pattern can lead to unnecessarily long durations and elevated costs, especially when repeated across high-volume workflows or under memory-intensive configura",medium,published
CER-005270,aws,focus_compute,aws-lambda,Excessive Lambda Retries (Retry Storms),"Retry storms occur when a function fails and is automatically retried repeatedly due to default retry behavior for asynchronous events (e.g., SQS, EventBridge). If the error is persistent and unhandled, retries can accumulate rapidly — often invisibly — creating a large volume of billable executions with no successful outcome. This is especially costly when functions run for extended durations or ",medium,published
CER-001658,aws,focus_storage,aws-s3,Excessive ListBucket API Calls to an S3 Bucket,"ListBucket requests are commonly used to enumerate objects in a bucket, such as by backup systems, scheduled sync jobs, data catalogs, or monitoring tools. When these operations are frequent or target buckets with large object counts, they can generate disproportionately high request charges. In many cases, real-time enumeration is not necessary and can be replaced with more efficient alternatives",medium,published
CER-002074,gcp,focus_ai,gcp-vertex-ai,Excessive Model Logging Enabled in Production Environments,"Verbose logging is useful during development, but many teams forget to disable it before deploying to production. Generative AI workloads often include long prompts, large multi-paragraph outputs, embedding vectors, and structured metadata. When these full payloads are logged on high-throughput production endpoints, Cloud Logging costs can quickly exceed the cost of the model inference itself. Thi",medium,published
CER-004643,azure,focus_storage,azure-blob-storage,Excessive Retention of Audit Logs,"Audit logs are often retained longer than necessary, especially in environments where the logging destination is not carefully selected. Projects that initially route SQL Audit Logs or other high-volume sources to LAW or Azure Storage may forget to revisit their retention strategy. Without policies in place, logs can accumulate unchecked—particularly problematic with SQL logs, which can generate s",medium,published
CER-007976,aws,focus_storage,aws-rds,Excessive Retention of Automated RDS Backups,"If backup retention settings are too high or old automated backups are unnecessarily retained, costs can accumulate rapidly. RDS backup storage is significantly more expensive than equivalent storage in S3. For long-term retention or compliance use cases, exporting backups to S3 (e.g., via snapshot export to Amazon S3 in Parquet) is often more cost-effective than retaining them in RDS-native forma",medium,published
CER-002316,gcp,focus_other,gcp-cloud-logging,Excessive Retention of Logs in Cloud Logging,"By default, Cloud Logging retains logs for 30 days. However, many organizations increase retention to 90 days, 365 days, or longer — even for non-critical logs such as debug-level messages, transient system logs, or audit logs in dev environments. This extended retention can lead to unnecessary costs, especially when: * Logs are never queried after the first few days * Observability tooling duplic",medium,published
CER-009101,gcp,focus_ai,gcp-vertex-ai,Excessive Retries for Large Inference Outputs,"Generative workloads that produce long outputs—such as detailed summaries, document rewrites, or multi-paragraph chat completions—require extended model runtime.",medium,published
CER-002135,gcp,focus_database,gcp-bigtable,Excessive Shard Count in GCP Bigtable,"Bigtable automatically splits data into tablets (shards), which are distributed across provisioned nodes. However, poorly designed row key schemas or excessive shard counts (caused by high cardinality, hash-based keys, or timestamp-first designs) can result in performance bottlenecks or hot spotting. To compensate, users often scale up node counts — increasing costs — when the real issue lies in s",medium,published
CER-004350,snowflake,focus_storage,snowflake-snapshots,Excessive Snapshot Storage from High-Churn Snowflake Tables,"Snowflake automatically maintains previous versions of data when tables are modified or deleted. For tables with high churn—meaning frequent INSERT, UPDATE, DELETE, or MERGE operations—this can cause a significant buildup of historical snapshot data, even if the active data size remains small.This hidden accumulation leads to elevated storage costs, particularly when Time Travel retention periods ",medium,published
CER-009040,aws,focus_other,aws-marketplace,Hidden Marketplace Spend Preventing Commitment Optimization,"In many organizations, AWS Marketplace purchases are lumped into a single consolidated billing line without visibility into individual vendors. This lack of transparency makes it difficult to identify which Marketplace spend is eligible to count toward the EDP cap. As a result, teams may either overspend on direct AWS services to fulfill their commitment unnecessarily or miss the opportunity to ri",medium,published
CER-008411,azure,focus_storage,azure-blob-storage,High Transaction Cost Due to Misaligned Tier in Azure Blob Storage,"Azure Blob Storage tiers are designed to optimize cost based on access frequency. However, when frequently accessed data is stored in the Cool or Archive tiers—either due to misconfiguration, default settings, or cost-only optimization—transaction costs can spike. These tiers impose significantly higher charges for read/write operations and metadata access compared to the Hot tier.This misalignmen",medium,published
CER-003782,azure,focus_storage,azure-files,High Transaction Cost Due to Misaligned Tier in Azure Files,"Azure Files Standard tier is cost-effective for low-traffic scenarios but imposes per-operation charges that grow rapidly with frequent access. In contrast, Premium tier provides consistent IOPS and throughput without additional transaction charges. When high-throughput or performance-sensitive workloads (e.g., real-time application data, logs, user file interactions) are placed in the Standard ti",medium,published
CER-001438,azure,focus_compute,azure-app-service,Idle Azure App Service Plan Without Deployed Applications,"App Service Plans continue to incur charges even when no applications are deployed. This can occur when applications are deleted, migrated, or retired, but the associated App Service Plan remains active. Without ongoing workloads, these idle plans become silent cost contributors — especially in higher-cost SKUs like Premium v3 or Isolated v2.In large or decentralized environments, unused plans can",medium,published
CER-007459,azure,focus_database,azure-sql,Idle Azure SQL Elastic Pool Without Databases,"An Azure SQL Elastic Pool continues to incur costs even if it contains no databases. This can occur when databases are deleted, migrated to single-instance configurations, or consolidated elsewhere — but the pool itself remains provisioned. In such cases, the pool becomes an idle resource consuming budget without delivering value.This inefficiency often goes undetected in large or decentralized en",medium,published
CER-008659,gcp,focus_database,gcp-cloud-memorystore,Idle Cloud Memorystore Redis Instance,"Cloud Memorystore instances that remain idle—i.e., not receiving read or write requests—continue to incur full costs based on provisioned size. In test environments, migration scenarios, or deprecated application components, Redis instances are often left running unintentionally. Since Redis does not autoscale or suspend, unused capacity results in 100% waste until explicitly deleted.",medium,published
CER-001319,gcp,focus_network,gcp-cloud-nat,Idle Cloud NAT Gateway Without Active Traffic,"Each Cloud NAT gateway provisioned in GCP incurs hourly charges for each external IP address attached, regardless of whether traffic is flowing through the gateway. In many environments, NAT configurations are created for temporary access (e.g., one-off updates, patching windows, or ephemeral resources) and are never cleaned up. If no traffic is flowing, these NAT gateways remain idle yet continue",medium,published
CER-002163,gcp,focus_compute,gcp-dataflow,Idle Dataflow Workers Running After Pipeline Failure,"When a Dataflow pipeline fails—often due to dependency issues, misconfigurations, or data format mismatches—its worker instances may remain active temporarily until the service terminates them. In some cases, misconfigured jobs, stuck retries, or delayed monitoring can cause workers to continue running for extended periods. These idle workers consume vCPU, memory, and storage resources without per",medium,published
CER-007739,aws,focus_compute,aws-ecs,Idle ECS Container Instances Due to ASG Minimum Capacity,"When ECS clusters are configured with an Auto Scaling Group that maintains a minimum number of EC2 instances (e.g., min = 1 or higher), the instances remain active even when there are no tasks scheduled. This leads to idle compute capacity and unnecessary EC2 charges.Instead, ECS Capacity Providers support target tracking scaling policies that can scale the ASG to zero when idle and automatically ",medium,published
CER-001832,aws,focus_compute,aws-emr,Idle EMR Cluster Without Auto-Termination Policy,"Amazon EMR clusters often run on large, multi-node EC2 fleets, making them costly to leave running unnecessarily. If a cluster becomes idle—no longer processing jobs—but is not terminated, it continues accruing EC2 and EMR service charges. Many teams forget to shut down clusters manually or leave them running for debugging, staging, or future job use. Without an auto-termination policy, this overs",medium,published
CER-002813,gcp,focus_compute,gcp-gke,Idle GKE Autopilot Clusters with Always-On System Overhead,"Even when no user workloads are active, GKE Autopilot clusters continue running system-managed pods that accrue compute and storage charges. These include control plane components and built-in agents for observability and networking. If Autopilot clusters are deployed in non-production or experimental environments and left idle, they may silently accrue ongoing charges unrelated to application act",medium,published
CER-005478,gcp,focus_network,gcp-load-balancers,Idle Load Balancer,"Provisioned load balancers continue to generate costs even when they are no longer serving meaningful traffic. This often occurs when applications are decommissioned, testing infrastructure is left behind, or backend services are removed without deleting the associated frontend configurations. Without ingress or egress traffic, these load balancers offer no functional value but still consume billa",medium,published
CER-004131,aws,focus_network,aws-data-transfer,Imbalanced Data Transfer Between Availability Zones,"Some architectures unintentionally route large volumes of traffic between resources that reside in different Availability Zones—such as database queries, service calls, replication, or logging. While these patterns may be functionally correct, they can lead to unnecessary data transfer charges when the traffic could be contained within a single AZ. Over time, this can become a silent cost driver, ",medium,published
CER-002606,aws,focus_compute,aws-workspaces,Inactive AWS WorkSpace,"If an AWS WorkSpace has been provisioned but not accessed in a meaningful timeframe, it may represent waste—particularly if it is set to monthly billing. Many organizations leave WorkSpaces active for users who no longer need them or have shifted roles, leading to persistent charges without corresponding business value. Even in hourly mode, costs can accrue if WorkSpaces are left in a running stat",medium,published
CER-004680,aws,focus_compute,aws-appstream-2-0,Inactive AppStream Image Builder or App Block Builder Instances,"When AppStream builder instances are left running but unused, they continue to generate compute charges without delivering any value. These instances are commonly left active after configuration or image creation is completed but can be safely stopped or terminated when not in use. Identifying and decommissioning inactive builders helps reduce unnecessary compute costs.",medium,published
CER-008365,aws,focus_network,aws-elb,Inactive Application Load Balancer (ALB),"Application Load Balancers that no longer serve active workloads may persist after application migrations, architecture changes, or testing activities. When no incoming requests are processed through the ALB, it continues to generate baseline hourly and LCU charges. Identifying and decommissioning unused ALBs helps reduce networking expenses without impacting operational environments.",medium,published
CER-009911,azure,focus_network,azure-load-balancer,Inactive Azure Load Balancer,"In dynamic environments — especially during autoscaling, testing, or infrastructure changes — it's common for load balancers to remain provisioned after their backend resources have been decommissioned. When this happens, the load balancer continues to incur hourly charges despite serving no functional purpose. These inactive resources often go unnoticed, particularly in dev/test environments or w",medium,published
CER-009868,azure,focus_network,azure-load-balancer,Inactive Azure Load Balancer,"Standard Load Balancers are frequently provisioned for internal services, internet-facing applications, or testing environments. When a workload is decommissioned or moved, the load balancer may be left behind without any active backend pool or traffic — but continues to incur hourly charges for each frontend IP configuration.Because Azure does not automatically remove or alert on inactive load ba",medium,published
CER-008957,azure,focus_storage,azure-blob-storage,Inactive Blobs in Storage Account,"Storage accounts can accumulate blob data that is no longer actively accessed—such as legacy logs, expired backups, outdated exports, or orphaned files. When these blobs remain in the Hot tier, they continue to incur the highest storage cost, even if they have not been read or modified for an extended period. Without lifecycle management in place, these inactive blobs often go unnoticed and accumu",medium,published
CER-003251,aws,focus_network,aws-elb,Inactive Classic Load Balancer (CLB),"Classic Load Balancers that no longer serve active workloads will persist if they are not properly decommissioned. This often happens after application migrations, architecture changes, or testing activities. Even if no connections or traffic are passing through the CLB, it continues to incur baseline charges until manually deleted. Identifying and removing unused load balancers helps eliminate wa",medium,published
CER-008098,aws,focus_other,aws-cloudwatch,Inactive CloudWatch Log Group,"CloudWatch log groups often persist long after their usefulness has expired. In some cases, they are associated with applications or resources that are no longer active. In other cases, the systems may still be running, but the log data is no longer being reviewed, analyzed, or used by any team. Regardless of the reason, retaining logs that no one is monitoring or using results in unnecessary stor",medium,published
CER-004018,aws,focus_database,aws-dms,Inactive DMS Replication Instance,"Replication instances are commonly left running after migration tasks are completed, especially when DMS is used for one-time or project-based migrations. Without active replication tasks, these instances no longer serve any purpose but continue to incur hourly compute costs. In large organizations or decentralized migration projects, these idle instances may go unnoticed, contributing to persiste",medium,published
CER-004839,aws,focus_database,aws-dynamodb,Inactive DynamoDB Table,"This inefficiency occurs when a DynamoDB table is no longer accessed by any active workload but continues to accumulate storage charges. These tables often remain after a project ends, a feature is retired, or data is migrated elsewhere. Without any read or write activity, the table provides no functional value and becomes a cost liability.",medium,published
CER-006784,aws,focus_compute,aws-ec2,Inactive EC2 Instance,"This inefficiency occurs when an EC2 instance remains in a running state but is not actively utilized. These instances may be remnants of past projects, forgotten development environments, or temporarily created for testing and never decommissioned. If an instance shows consistently low or no CPU, network, or disk activity—and no active connections—it likely serves no operational purpose but conti",medium,published
CER-006372,aws,focus_compute,aws-eks,Inactive EKS Cluster,"Clusters that no longer run active workloads but remain provisioned continue incurring hourly control plane costs and may also maintain associated infrastructure like node groups or VPC components. Inactive clusters often persist after environment decommissioning, project shutdowns, or migrations. Decommissioning unused clusters eliminates unnecessary operational costs and simplifies infrastructur",medium,published
CER-008736,azure,focus_storage,azure-blob-storage,Inactive Files in Storage Account,"Files that show no read or write activity over an extended period often indicate redundant or abandoned data. Keeping inactive files in higher-cost storage classes unnecessarily increases monthly spend. Implementing proactive archiving, deletion workflows, and safety features like Blob Soft Delete or Versioning improves cost efficiency while protecting against accidental data loss.",medium,published
CER-005248,gcp,focus_storage,gcp-gcs,Inactive GCS Bucket,"GCS buckets often persist after applications are retired or data is no longer in active use. Without access activity, these buckets generate storage charges without providing ongoing value. Leaving stale data in Standard storage—designed for frequent access—results in unnecessary cost. If the data must be retained for compliance or future reference, colder tiers offer substantial savings. If it is",medium,published
CER-001244,aws,focus_network,aws-elb,Inactive Gateway Load Balancer (GLB),"Gateway Load Balancers that no longer have active traffic flows can continue to exist indefinitely unless proactively decommissioned. This often happens after network topology changes, security architecture updates, or environment deprecations. Without active packet forwarding, the GLB provides no functional benefit but still incurs hourly and data transfer costs.",medium,published
CER-008474,aws,focus_compute,aws-eks,Inactive Kubernetes Workload,"Workloads with consistently low CPU and memory usage may no longer serve active traffic or scheduled tasks, but continue reserving resources within the cluster. These idle deployments often remain after project migrations, feature deprecations, or experimentation. Removing inactive workloads allows node groups to scale down, reducing infrastructure costs without impacting active services.",medium,published
CER-007888,gcp,focus_database,gcp-memorystore,Inactive Memorystore Instance,"Memorystore instances that are provisioned but unused — whether due to deprecated services, orphaned environments, or development/testing phases ending — continue to incur memory and infrastructure charges. Because usage-based metrics like client connections or cache hit ratios are not tied to billing, an idle instance costs the same as a heavily used one. This makes it critical to identify and de",medium,published
CER-007739,aws,focus_network,aws-nat-gateway,Inactive NAT Gateway,"NAT Gateways are frequently left running after environments are re-architected, workloads are shut down, or connectivity patterns change. In many cases, they continue to incur hourly charges despite no active traffic flowing through them. Because hourly fees are not tied to whether the gateway is needed—just whether it exists—these resources can quietly drive recurring costs without delivering ong",medium,published
CER-007760,aws,focus_network,aws-elb,Inactive Network Load Balancer (NLB),"Network Load Balancers that are no longer needed often persist after architecture changes, service decommissioning, or migration projects. When no active TCP connections or traffic flow through the NLB, it still generates hourly operational costs. Identifying and removing these idle resources helps reduce unnecessary networking expenses without affecting service availability.",medium,published
CER-005856,oci,focus_storage,oci-object-storage,Inactive Object Storage Bucket,"OCI Object Storage buckets accrue charges based on data volume stored, even if no activity has occurred. Buckets that haven't been read from or written to in months may contain outdated data or artifacts from discontinued projects.",medium,published
CER-009353,aws,focus_database,aws-rds,Inactive RDS Cluster,"This inefficiency occurs when an RDS cluster remains provisioned but is no longer serving any workloads and has no active database connections. Unlike underutilized resources, these clusters are completely idle—showing no query activity, background processing, or usage over time. They often persist in dev, staging, or legacy environments where the workload has been retired or moved, yet the cluste",medium,published
CER-003583,aws,focus_database,aws-rds,Inactive RDS Instance,"This inefficiency occurs when an RDS instance remains in the running state but is no longer actively serving application traffic. These instances may be remnants of retired applications, paused development environments, or workloads that were migrated elsewhere. If an instance shows no active connections and sustained inactivity across CPU and memory metrics, it is likely idle and generating unnec",medium,published
CER-002996,aws,focus_database,aws-rds,Inactive RDS Read Replica,"Read replicas are intended to improve performance for read-heavy workloads or support cross-region redundancy. However, it's common for replicas to remain in place even after their intended purpose has passed. In some cases, they were provisioned for scaling or analytics workloads that no longer exist; in others, they are tied to live environments but not actively receiving queries. Since each rep",medium,published
CER-008589,aws,focus_storage,aws-s3,Inactive S3 Bucket,"S3 buckets often persist after projects complete or when the associated workloads have been retired. If a bucket is no longer being read from or written to—and its contents are not required for compliance, backup, or retention purposes—it represents ongoing cost without delivering value. Many organizations overlook these idle buckets, especially in shared or legacy accounts, leading to unnecessary",medium,published
CER-009154,azure,focus_storage,azure-table-storage,Inactive Tables in Storage Account,"Tables with no read or write activity often represent deprecated applications, obsolete telemetry, or abandoned development artifacts. Retaining inactive tables increases storage costs and operational complexity. Regularly auditing and cleaning up unused tables helps maintain a streamlined, cost-effective storage environment.",medium,published
CER-001988,aws,focus_network,aws-vpc,Inactive VPC Interface Endpoint,"VPC Interface Endpoints are commonly deployed to meet network security or compliance requirements by enabling private access to AWS services. However, these endpoints often remain provisioned even after the original use case is deprecated. In some cases, the applications have been decommissioned; in others, traffic routing has changed and the endpoint is no longer used. Since interface endpoints g",medium,published
CER-005932,azure,focus_network,azure-waf,Inactive Web Application Firewall (WAF),"Azure WAF configurations attached to Application Gateways can persist after their backend pool resources have been removed — often during environment reconfiguration or application decommissioning. In these cases, the WAF is no longer serving any functional purpose but continues to incur fixed hourly costs. Because no traffic is routed and no applications are protected, the WAF is effectively inac",medium,published
CER-006653,aws,focus_storage,aws-ebs,Inactive and Detached EBS Volume,"EBS volumes frequently remain detached after EC2 instances are terminated, replaced, or reconfigured. Some may be intentionally retained for reattachment or backup purposes, but many persist unintentionally due to the lack of automated cleanup. When these detached volumes are also inactive—showing no read or write activity—they represent unnecessary ongoing costs. Identifying and removing these or",medium,published
CER-005257,azure,focus_storage,azure-managed-disks,Inactive and Detached Managed Disk,"Managed Disks frequently remain detached after Azure virtual machines are deleted, reimaged, or reconfigured. Some may be intentionally retained for reattachment, backup, or migration purposes, but many persist unintentionally due to the lack of automated cleanup processes. When these detached disks are also inactive—showing no read or write activity—they represent unnecessary ongoing costs. Ident",medium,published
CER-007500,azure,focus_compute,azure-virtual-machines,Inactive and Stopped VM,"This inefficiency arises when a virtual machine is left in a stopped (deallocated) state for an extended period but continues to incur costs through attached storage and associated resources. These idle VMs are often remnants of retired workloads, temporary environments, or paused projects that were never fully cleaned up. Without clear ownership or automated cleanup, they can persist unnoticed an",medium,published
CER-002770,aws,focus_storage,aws-efs,Inactive and Unmounted EFS File System,"EFS file systems that are no longer attached to any running services — such as EC2 instances or Lambda functions — continue to incur storage charges. This often occurs after workloads are decommissioned but the file system is left behind. A quick indicator of this state is when the EFS file system has no mount targets configured. Without active usage or connection, these orphaned file systems repr",medium,published
CER-001898,databricks,focus_compute,databricks-clusters,Inefficient Autotermination Configuration for Interactive Clusters,"Interactive clusters are often left running between periods of active use. To mitigate idle charges, Databricks provides an “autotermination” setting that shuts down clusters after a period of inactivity. However, if the termination period is set too high, or if policies do not enforce reasonable thresholds, idle clusters can persist for long durations without performing any work—resulting in wast",medium,published
CER-006762,databricks,focus_compute,interactive-clusters,Inefficient BI Queries Driving Excessive Compute Usage,Business Intelligence dashboards and ad-hoc analyst queries frequently drive Databricks compute usage — especially when: * Dashboards are auto-refreshed too frequently * Queries scan full datasets instead of leveraging filtered views or materialized tables * Inefficient joins or large broadcast operations are used * Redundant or exploratory queries are triggered during interactive exploration This,medium,published
CER-004453,snowflake,focus_compute,snowflake-query-processing,Inefficient Execution of Repeated Queries,"Inefficient execution of repeated queries occurs when common query patterns are frequently executed without optimization. Even if individual executions are successful, repeated inefficiencies compound overall compute consumption and credit costs.By analyzing Snowflake's parameterized query metrics, organizations can identify top repeated queries and optimize them for better performance, resource u",medium,published
CER-009503,aws,focus_compute,aws-athena,Inefficient File Format and Layout for Athena Queries,"Storing raw JSON or CSV files in S3—especially when written frequently in small batches—leads to excessive scan costs in Athena. These formats are row-based and verbose, requiring Athena to scan and parse the full content even when only a few fields are queried. Without columnar formats, partitioning, or metadata-aware table formats, queries become inefficient and expensive, especially in high-vol",medium,published
CER-004439,snowflake,focus_other,snowflake-tasks-and-pipelines,Inefficient Pipeline Refresh Scheduling,"Inefficient pipeline refresh scheduling occurs when data refresh operations are executed more frequently, or with more compute resources, than the actual downstream business usage requires.Without aligning refresh frequency and resource allocation to true data consumption patterns (e.g., report access rates in Tableau or Sigma), organizations can waste substantial Snowflake credits maintaining und",medium,published
CER-002429,azure,focus_other,azure-databricks,Inefficient Private Link Routing to Azure Databricks,"In Azure Databricks environments that rely on Private Link for secure networking, it’s common to route traffic through multi-tiered network architectures. This often includes multiple VNets, Private Link endpoints, or peered subscriptions between data sources (e.g., ADLS) and the Databricks compute plane. While these architectures may be designed for isolation or compliance, they frequently introd",medium,published
CER-006667,aws,focus_compute,aws-ec2,Inefficient Processor Selection in EC2 Instances,"Many organizations default to Intel-based EC2 instances due to familiarity or assumptions about workload compatibility. However, AWS offers AMD and Graviton-based alternatives that often deliver significantly better price-performance for general-purpose and compute-optimized workloads.By not testing workloads across available architectures, teams may continue paying a premium for Intel instances e",medium,published
CER-004415,databricks,focus_compute,databricks-sql,Inefficient Query Design in Databricks SQL and Spark Jobs,"Many Spark and SQL workloads in Databricks suffer from micro-optimization issues — such as unfiltered joins, unnecessary shuffles, missing broadcast joins, and repeated scans of uncached data. These problems increase compute time and resource utilization, especially in exploratory or development environments. Disabling Adaptive Query Execution (AQE) can further exacerbate inefficiencies. Optimizin",medium,published
CER-005876,aws,focus_compute,aws-lambda,Inefficient SnapStart Configuration in Lambda,"SnapStart reduces cold-start latency, but when configured inefficiently, it can increase costs. High-traffic workloads can trigger frequent snapshot restorations, multiplying costs. Slow initialization code inflates the Init phase, which is now billed at the full rate. Suppressed-init conditions, where functions initialize without enhanced resources, can add further inefficiency if memory or timeo",medium,published
CER-008418,snowflake,focus_other,snowflake-snowpipe,Inefficient Snowpipe Usage Due to Small File Ingestion,"Ingesting a large number of small files (e.g., files smaller than 10 MB) using Snowpipe can lead to disproportionately high costs due to the per-file overhead charges. Each file, regardless of its size, incurs the same overhead fee, making the ingestion of numerous small files less cost-effective. Additionally, small files can increase the load on Snowflake's metadata and ingestion infrastructure,",medium,published
CER-004682,azure,focus_other,azure-pipelines,Inefficient Use of Azure Pipelines,"Teams often overuse Microsoft-hosted agents by running redundant or low-value jobs, failing to configure pipelines efficiently, or neglecting to use self-hosted agents for steady workloads. These inefficiencies result in unnecessary cost and delivery friction, especially when pipelines create queues due to limited agent availability.",medium,published
CER-003587,databricks,focus_compute,databricks-clusters,Inefficient Use of Interactive Clusters,"Interactive clusters are intended for development and ad-hoc analysis, remaining active until manually terminated. When used to run scheduled jobs or production workflows, they often stay idle between executions—leading to unnecessary infrastructure and DBU costs. Job clusters are designed for ephemeral, single-job execution and automatically terminate upon completion, reducing runtime and isolati",medium,published
CER-007085,databricks,focus_other,databricks-workflows,Inefficient Use of Job Clusters in Databricks Workflows,"When multiple tasks within a workflow are executed on separate job clusters — despite having similar compute requirements — organizations incur unnecessary overhead. Each cluster must initialize independently, adding latency and cost. This results in inefficient resource usage, especially for workflows that could reuse the same cluster across tasks. Consolidating tasks onto a single job cluster wh",medium,published
CER-003770,aws,focus_database,aws-dynamodb,Inefficient Use of On-Demand Capacity in DynamoDB,"While On-Demand mode is well-suited for unpredictable or bursty workloads, it is often cost-inefficient for applications with consistent throughput. In these cases, shifting to Provisioned mode with Auto Scaling allows teams to set a baseline level of capacity and scale incrementally as needed—often yielding substantial cost savings without compromising performance.",medium,published
CER-007871,azure,focus_compute,databricks,Inefficient Use of Photon Engine in Azure Databricks,"Photon is optimized for SQL workloads, delivering significant speedups through vectorized execution and native C++ performance. However, Photon only accelerates workloads that use compatible operations and data patterns. If a workload includes unsupported functions, unoptimized joins, or falls back to interpreted execution, Photon may be silently bypassed — even on a Photon-enabled cluster. In thi",medium,published
CER-003622,databricks,focus_compute,databricks-clusters,Inefficient Use of Photon Engine in Databricks Compute,"Photon is enabled by default on many Databricks compute configurations. While it can accelerate certain SQL and DataFrame operations, its performance benefits are workload-specific and may not justify the increased DBU cost. Many pipelines, particularly ETL jobs or simpler Spark workloads, do not benefit materially from Photon but still incur the higher DBU multiplier. Disabling Photon by default ",medium,published
CER-007941,aws,focus_database,aws-rds,Inefficient Use of RDS Reader Nodes,"RDS reader nodes are intended to handle read-only workloads, allowing for traffic offloading from the primary (writer) node. However, in many environments, services are misconfigured or hardcoded to send all traffic—including reads—to the writer node. This results in underutilized reader nodes that still incur full hourly charges, while the writer node becomes a performance bottleneck and may requ",medium,published
CER-007511,gcp,focus_database,gcp-bigquery,Inefficient Use of Reservations in BigQuery,"Teams often adopt flat-rate pricing (slot reservations) to stabilize costs or optimize for heavy, recurring workloads. However, if query volumes drop — due to seasonal cycles, architectural shifts (e.g., workload migration), or inaccurate forecasting — those reserved slots may sit underused. This inefficiency is easy to miss, as the cost remains fixed and detached from usage volume. Unlike autosca",medium,published
CER-004309,aws,focus_compute,aws-step-functions,Inefficient Workflow Design in AWS Step Functions,"Improper design choices in AWS Step Functions can lead to unnecessary charges. For example: * Using Standard Workflows for short-lived, high-frequency executions leads to excessive per-transition charges. * Using Express Workflows for long-running processes (close to or exceeding the 5-minute limit) may cause timeouts or retries. * Inefficient use of states—such as chaining many simple states inst",medium,published
CER-006034,snowflake,focus_compute,snowflake-virtual-warehouse,Inefficient Workload Distribution Across Warehouses,"Many organizations assign separate Snowflake warehouses to individual business units or teams to simplify chargebacks and operational ownership. This often results in redundant and underutilized warehouses, as workloads frequently do not require the full capacity of even the smallest warehouse size.By consolidating compatible workloads onto shared warehouses, organizations can maximize utilization",medium,published
CER-004766,azure,focus_database,azure-cosmos-db,Infrequently Accessed Data Stored in Azure Cosmos DB,"Azure Cosmos DB is optimized for low-latency, globally distributed workloads—not long-term storage of infrequently accessed data. Yet in many environments, cold data such as logs, telemetry, or historical records is retained in Cosmos DB due to a lack of lifecycle management.",medium,published
CER-007015,aws,focus_storage,aws-s3,Infrequently Accessed Objects Stored in S3 Standard Tier,"S3 Standard is the default storage class and is often used by default even for data that is rarely accessed. Keeping large volumes of infrequently accessed data in S3 Standard leads to unnecessary costs. Data such as backups, logs, archives, or historical snapshots are often strong candidates for migration to colder tiers like S3 Glacier or Deep Archive. If access patterns are unknown or variable,",medium,published
CER-001682,aws,focus_storage,aws-backup,Lack of Deduplication and Change Block Tracking in AWS Backup,"AWS Backup does not natively support global deduplication or change block tracking across backups. As a result, even traditional incremental or differential backup strategies (e.g., daily incremental, weekly full) can accumulate redundant data. Over time, this leads to higher-than-necessary storage usage and cost — especially in environments with frequent backup schedules or large data volumes tha",medium,published
CER-006847,databricks,focus_other,databricks,Lack of Functional Cost Attribution in Databricks Workloads,"Databricks cost optimization begins with visibility. Unlike traditional IaaS services, Databricks operates as an orchestration layer spanning compute, storage, and execution — but its billing data often lacks granularity by workload, job, or team. This creates a visibility gap: costs fluctuate without clear root causes, ownership is unclear, and optimization efforts stall due to lack of actionable",medium,published
CER-005609,databricks,focus_compute,databricks-clusters,Lack of Graviton Usage in Databricks Clusters,"Databricks supports AWS Graviton-based instances for most workloads, including Spark jobs, data engineering pipelines, and interactive notebooks. These instances offer significant cost advantages over traditional x86-based VMs, with comparable or better performance in many cases. When teams default to legacy instance types, they miss an easy opportunity to reduce compute spend. Unless workloads ha",medium,published
CER-007521,databricks,focus_compute,databricks-compute,Lack of Workload-Specific Cluster Segmentation,"Running varied workload types (e.g., ETL pipelines, ML training, SQL dashboards) on the same cluster introduces inefficiencies. Each workload has different runtime characteristics, scaling needs, and performance sensitivities. When mixed together, resource contention can degrade job performance, increase cost, and obscure cost attribution.ETL jobs may overprovision memory, while lightweight SQL qu",medium,published
CER-004314,azure,focus_other,azure-marketplace,Lifecycle Visibility Gaps Inflating Renewal Costs in Azure Marketplace,"When Marketplace contracts or subscriptions expire or change without visibility, Azure may automatically continue billing at higher on-demand or list prices. These lapses often go unnoticed due to lack of proactive tracking, ownership, or renewal alerts, resulting in substantial cost increases. The issue is amplified when contract records are siloed across procurement, finance, and engineering tea",medium,published
CER-002637,gcp,focus_other,gcp-cloud-logging,Logging Buckets in Non-Production Environments Storing Info Logs,"Non-production environments frequently generate INFO-level logs that capture expected system behavior or routine API calls. While useful for troubleshooting in development, they rarely need to be retained. Allowing all INFO logs to be ingested and stored in Logging buckets across dev or staging environments can lead to disproportionate ingestion and storage costs. This inefficiency often persists ",medium,published
CER-008855,azure,focus_storage,azure-snapshots,Long-Retained Azure Snapshot,"Snapshots are often created for short-term protection before changes to a VM or disk, but many remain in the environment far beyond their intended lifespan. Over time, this leads to an accumulation of snapshots that are no longer associated with any active resource or retained for operational need.Since Azure does not enforce automatic expiration or lifecycle policies for snapshots, they can persi",medium,published
CER-003032,aws,focus_database,aws-rds,Long-Retained RDS Manual Snapshot,"Manual snapshots are often created for operational tasks like upgrades, migrations, or point-in-time backups. Unlike automated backups, which are automatically deleted after a set retention period, manual snapshots remain in place until explicitly deleted. Over time, this can lead to an accumulation of snapshots that are no longer needed but still incur monthly storage charges. This is particularl",medium,published
CER-008052,azure,focus_storage,azure-managed-disks,Managed Disk Attached to a Deallocated VM,"This inefficiency occurs when a VM is deallocated but its attached managed disks are still active and incurring storage charges. While compute billing stops for deallocated VMs, the disks remain provisioned and billable. These disks often persist unintentionally after a VM is paused, retired, or left unused in dev/test environments, resulting in waste if not explicitly cleaned up.",medium,published
CER-003227,azure,focus_storage,azure-managed-disks,Managed Disk Attached to a Stopped VM,"Disks attached to VMs that have been stopped for an extended period, particularly when showing no read or write activity, may indicate abandoned infrastructure or obsolete resources. Retaining these disks without validation leads to unnecessary monthly storage costs. Reviewing and cleaning up inactive disks helps optimize spend and maintain storage hygiene.",medium,published
CER-008089,aws,focus_network,aws-nat-gateway,Managed NAT Gateway with Excessive Data Transfer,"NAT Gateways are convenient for enabling outbound access from private subnets, but in data-intensive environments, they can quietly become a major cost driver. When large volumes of traffic flow through the gateway—particularly during batch processing, frequent software updates, or hybrid cloud integrations—the per-GB charges accumulate rapidly. In some cases, replacing a managed NAT Gateway with ",medium,published
CER-002410,aws,focus_storage,aws-s3,Misaligned S3 Storage Tier Selection Based on Access Patterns,"While moving objects to colder storage classes like Glacier or Infrequent Access (IA) can reduce storage costs, premature transitions without analyzing historical access patterns can lead to unintended expenses. Retrieval charges, restore time delays, and early delete penalties often go unaccounted for in simplistic tiering decisions. This inefficiency arises when teams default to colder tiers bas",medium,published
CER-002210,databricks,focus_compute,databricks-clusters,Missing Auto-Termination Policy for Databricks Clusters,"In many environments, users launch Databricks clusters for development or analysis and forget to shut them down after use. When no auto-termination policy is configured, these clusters remain active indefinitely, incurring unnecessary charges for both Databricks and cloud infrastructure usage. This inefficiency is especially common in interactive clusters that are user-managed, ephemeral, or explo",medium,published
CER-008607,gcp,focus_storage,gcp-gcs,Missing Autoclass on GCS Bucket,"Buckets without Autoclass enabled can accumulate infrequently accessed data in more expensive storage classes, inflating monthly costs. Enabling Autoclass allows GCS to automatically move objects to lower-cost tiers based on observed access behavior, optimizing storage costs without manual lifecycle policy management. Activating Autoclass reduces operational overhead while maintaining seamless acc",medium,published
CER-007131,databricks,focus_storage,delta-lake,Missing Delta Optimization Features for High-Volume Tables,"In many Databricks environments, large Delta tables are created without enabling standard optimization features like partitioning and Z-Ordering. Without these, queries scanning large datasets may read far more data than necessary, increasing execution time and compute usage. * Partitioning organizes data by a specified column to reduce scan scope. * Z-Ordering optimizes file sorting to minimize I",medium,published
CER-008760,aws,focus_storage,aws-efs,Missing Intelligent-Tiering on EFS Lifecycle Policy,"EFS offers lifecycle policies that transition files from the Standard tier to Infrequent Access (IA) based on inactivity, significantly reducing storage costs for cold data. When this feature is not enabled, infrequently accessed files remain in the more expensive Standard tier indefinitely. This often occurs when the file system is initially provisioned for performance but long-term access patter",medium,published
CER-001444,oci,focus_storage,oci-object-storage,Missing Lifecycle Policy on Object Storage,"Without lifecycle policies, data in OCI Object Storage remains in the default storage tier indefinitely—even if it is rarely accessed. This can lead to growing costs from unneeded or rarely accessed data that could be expired or transitioned to lower-cost tiers like Archive Storage.",medium,published
CER-007148,aws,focus_storage,aws-efs,Missing Lifecycle Policy on Replicated EFS File System,"When replicating an EFS file system across AWS regions (e.g., for disaster recovery), the destination file system does not automatically inherit the source’s lifecycle policy. As a result, files replicated to the destination will remain in the Standard storage class unless a new lifecycle policy is explicitly configured. Over time, this can lead to significantly higher storage costs, particularly ",medium,published
CER-009649,azure,focus_storage,azure-managed-disks,Missing Performance Plus on Eligible Managed Disks,"For Premium SSD and Standard SSD disks 513 GiB or larger, Azure now offers the option to enable Performance Plus — unlocking higher IOPS and MBps at no extra cost. Many environments that previously required custom performance settings continue to pay for additional throughput unnecessarily. By not enabling Performance Plus on eligible disks, organizations miss a straightforward opportunity to redu",medium,published
CER-002318,azure,focus_ai,azure-cognitive-services,Missing Reserved PTUs for Steady-State Azure OpenAI Workloads,"Many production Azure OpenAI workloads—such as chatbots, inference services, and retrieval-augmented generation (RAG) pipelines—use PTUs consistently throughout the day. When usage stabilizes after initial experimentation, continuing to rely on on-demand PTUs results in ongoing unnecessary spend. These workloads are strong candidates for reserved PTUs, which provide identical performance guarantee",medium,published
CER-008077,aws,focus_storage,aws-s3,Missing S3 Gateway Endpoint for Intra-Region EC2 Access,"When EC2 instances within a VPC access Amazon S3 in the same region without a Gateway VPC Endpoint, traffic is routed through the public S3 endpoint and incurs standard internet egress charges — even though it remains within the AWS network. This results in unnecessary egress charges, as AWS treats this traffic as data transfer out to the internet, billed under the S3 service.By contrast, provisio",medium,published
CER-003133,aws,focus_storage,aws-s3,Missing S3 Lifecycle Policy for Incomplete Multipart Uploads,"Multipart upload allows large files to be uploaded in segments. Each part is stored individually until the upload is finalized by a “CompleteMultipartUpload” request. If this final request is never issued—due to a timeout, crash, failed job, or misconfiguration—the parts remain stored but are effectively useless: they do not form a valid object and cannot be retrieved. Without a lifecycle policy i",medium,published
CER-005903,azure,focus_compute,azure-virtual-machines,Missing Scheduled Shutdown for Non-Production Azure Virtual Machines,"Non-production Azure VMs are frequently left running during off-hours despite being used only during business hours. When these instances remain active overnight or on weekends, they generate unnecessary compute spend. Azure offers built-in auto-shutdown features that allow teams to define daily stop times, retaining disk data and configurations without paying for VM runtime. Implementing schedule",medium,published
CER-005966,gcp,focus_compute,gcp-compute-engine,Missing Scheduled Shutdown for Non-Production Compute Engine Instances,"Development and test environments on Compute Engine are commonly provisioned and left running around the clock, even if only used during business hours. This results in wasteful spend on compute time that could be eliminated by scheduling shutdowns during idle periods. GCP enables scheduling via native tools such as Cloud Scheduler, Cloud Functions, or Terraform automation. Stopping VMs during off",medium,published
CER-009831,aws,focus_compute,aws-ec2,Missing Scheduled Shutdown for Non-Production EC2 Instances,"Non-production EC2 instances are often provisioned for daytime-only usage but remain running 24/7 out of convenience or oversight. This results in unnecessary compute charges, even if the workload is inactive for 16+ hours per day. AWS supports automated schedules to stop and start instances at predefined times, allowing organizations to retain data and instance configuration without paying for un",medium,published
CER-002313,azure,focus_compute,azure-reservations,Missing Shared Scope Configuration for Azure Reservations,"When reservations are scoped only to a single subscription, any unused capacity cannot be applied to matching resources in other subscriptions within the same tenant. This leads to underutilization of the committed reservation and continued on-demand charges in other parts of the organization. Enabling Shared scope allows all eligible subscriptions to consume the reservation benefit, improving uti",medium,published
CER-008908,aws,focus_network,aws-vpc,Missing VPC Endpoints for High-Volume AWS Service Access,"When EC2 instances, Lambda functions, or containerized workloads access AWS-managed services without VPC Endpoints, that traffic exits the VPC through a NAT Gateway or Internet Gateway. This introduces unnecessary egress charges and NAT processing costs, especially for data-intensive or high-frequency workloads.",medium,published
CER-005250,snowflake,focus_other,snowflake-materialized-views,Missing or Inefficient Use of Materialized Views,"Inefficiency arises when MVs are either underused or misused. When high-cost, repetitive queries are not backed by MVs, workloads consume unnecessary compute resources. When MVs exist but are rarely queried, their background refresh and storage costs accumulate without offsetting savings.Proper evaluation of workload patterns and strategic use of MVs is critical to achieve a net cost benefit.",medium,published
CER-008775,aws,focus_database,aws-aurora,Misuse of Aurora Serverless for Steady-State Workloads,"Aurora Serverless is designed for workloads with unpredictable or intermittent usage patterns that benefit from automatic scaling. However, when used for databases with constant load, the service’s elasticity offers little advantage and adds cost overhead. Serverless instances run continuously in steady workloads, resulting in persistent ACU billing at a higher effective rate than a provisioned cl",medium,published
CER-004346,aws,focus_database,aws-rds,No Lifecycle Management for Temporarily Stopped RDS Instances,"While stopping an RDS instance reduces runtime cost, AWS enforces a 7-day limit on stopped state. After this period, the instance is automatically restarted and resumes incurring compute charges — even if the database is still not needed. This creates waste in cases where teams intended to pause the environment but failed to manage its lifecycle beyond the 7-day window. Without proper automation o",medium,published
CER-002544,aws,focus_database,aws-elasticache,Non-Graviton ElastiCache Node on Eligible Workload,"Many Redis and Memcached clusters still use legacy x86-based node types (e.g., cache.r5, cache.m5) even though Graviton-based alternatives are available. In-memory workloads tend to be highly compatible with Graviton due to their simplicity and reliance on standard CPU and memory usage patterns.Unless constrained by architecture-specific extensions or strict compliance requirements, most ElastiCac",medium,published
CER-006409,aws,focus_database,aws-rds,Non-Graviton RDS Instance on Eligible Workload,"Many RDS workloads continue to run on older x86 instance types (e.g., db.m5, db.r5) even though compatible Graviton-based options (e.g., db.m6g, db.r6g) are widely available. These newer families deliver improved performance per vCPU and lower hourly costs, yet are often not adopted due to legacy defaults, inertia, or lack of awareness.When workloads are not tightly bound to architecture-specific ",medium,published
CER-005981,azure,focus_ai,azure-cognitive-services,Non-Production Azure OpenAI Deployments Using PTUs Instead of PAYG,"Development, testing, QA, and sandbox environments rarely have the steady, predictable traffic patterns needed to justify PTU deployments. These workloads often run intermittently, with lower throughput and shorter usage windows. When PTUs are assigned to such environments, the fixed hourly billing generates continuous cost with little utilization. Switching non-production workloads to PAYG aligns",medium,published
CER-009359,databricks,focus_compute,databricks-clusters,On-Demand-Only Configuration for Non-Production Databricks Clusters,"In non-production environments—such as development, testing, and experimentation—many teams default to on-demand nodes out of habit or caution. However, Databricks offers built-in support for using spot instances safely. Its job scheduler and cluster management system are designed to detect spot instance evictions and automatically replace them with on-demand nodes when necessary, making the use o",medium,published
CER-009912,gcp,focus_compute,gcp-gke,Orphaned Kubernetes Resources,"In GKE environments, it is common for unused Kubernetes resources to accumulate over time. Examples include Persistent Volume Claims (PVCs) that retain provisioned Persistent Disks, or Services of type LoadBalancer that continue to front GCP external load balancers even after the backing pods are gone. ConfigMaps and Secrets may also linger, creating operational overhead.These orphaned objects oft",medium,published
CER-009085,aws,focus_compute,aws-eks,Orphaned Kubernetes Resources,"In Kubernetes environments, resources such as ConfigMaps, Secrets, Services, and Persistent Volume Claims (PVCs) are often created dynamically by applications or deployment pipelines. When applications are removed or reconfigured, these resources may be left behind if not explicitly cleaned up. Over time, they accumulate as orphaned resources — not referenced by any live workload.Some of these obj",medium,published
CER-009913,azure,focus_compute,azure-aks,Orphaned Kubernetes Resources,"Kubernetes environments often accumulate unused resources over time as applications evolve. Common examples include Persistent Volume Claims (PVCs) backed by Azure Disks, Services that trigger load balancer provisioning, or stale ConfigMaps and Secrets. When the associated deployments or pods are removed, these resources may remain unless explicitly deleted.In AKS, this can lead to unmanaged costs",medium,published
CER-002976,azure,focus_compute,azure-aks,Orphaned and Overprovisioned Resources in AKS Clusters,"Clusters often accumulate unused components when applications are terminated or environments are cloned. These include PVCs backed by Managed Disks, Services that still front Azure Load Balancers, and test namespaces that are no longer maintained. Node pools are frequently overprovisioned, especially in multi-tenant or CI environments.The cost impact of these idle resources is magnified in organiz",medium,published
CER-001348,aws,focus_compute,aws-eks,Orphaned and Overprovisioned Resources in EKS Clusters,"In EKS environments, cluster sprawl can occur when workloads are removed but underlying resources remain. Common issues include persistent volumes no longer mounted by pods, services still backed by ELBs despite being unused, and overprovisioned nodes for workloads that no longer exist. Node overprovisioning can result from high CPU/memory requests or limits, DaemonSets running on every node, rest",medium,published
CER-009463,gcp,focus_compute,gcp-gke,Orphaned and Overprovisioned Resources in GKE Clusters,"As environments scale, GKE clusters tend to accumulate artifacts from ephemeral workloads, dev environments, or incomplete job execution. PVCs can continue to retain Persistent Disks, Services may continue to expose public IPs and provision load balancers, and node pools are often oversized for steady-state demand. This results in cloud spend that is not aligned with application activity.Organizat",medium,published
CER-001601,aws,focus_compute,aws-glue,Outdated AWS Glue Version for Python Jobs,"Newer AWS Glue versions—such as Glue 5.0—include significant performance optimizations for **Python-based** ETL jobs, often reducing runtime by 10–60%. These improvements do not require any code changes, making version upgrades a simple and impactful optimization. When jobs remain on older runtimes such as Glue 3.0 or 4.0, they execute more slowly, consume more DPUs, and incur unnecessary cost. Ad",medium,published
CER-008221,aws,focus_database,aws-aurora,Outdated Aurora Versions Triggering Extended Support Charges,"Customers often delay upgrading Aurora clusters due to compatibility concerns or operational overhead. However, when older versions such as MySQL 5.7 or PostgreSQL 11 move into Extended Support, AWS applies automatic surcharges to ensure continued patching. These charges affect all clusters regardless of usage, creating unnecessary cost exposure across both production and non-production environmen",medium,published
CER-008122,azure,focus_compute,azure-app-service,Outdated Azure App Service Plan,"Applications running on App Service V2 plans may incur higher operational costs and degraded performance compared to V3 plans. V2 uses older hardware generations that lack access to platform-level enhancements introduced in V3, including improved cold start times, faster scaling, and enhanced networking options.This inefficiency often arises from legacy deployments or default provisioning choices ",medium,published
CER-005729,aws,focus_compute,aws-eks,Outdated EKS Cluster Incurring Extended Support Charges,"When an EKS cluster remains on a Kubernetes version that has reached the end of standard support, AWS begins charging an additional Extended Support fee. These charges often arise from delays in upgrade cycles, uncertainty about workload compatibility, or overlooked legacy clusters. If the workload does not require the older version, continuing to run the cluster in this state results in unnecessa",medium,published
CER-002772,aws,focus_database,aws-elasticache,Outdated ElastiCache Node Type,"Some ElastiCache clusters continue to run on older-generation node types that have since been replaced by newer, more cost-effective options. This can happen due to legacy templates, lack of version validation, or infrastructure that has not been reviewed in years. Newer instance families often deliver better performance at a lower hourly rate. Modernizing to newer node types can reduce compute sp",medium,published
CER-008053,aws,focus_database,aws-elasticsearch,Outdated Elasticsearch Version Triggering Extended Support Charges,"Many legacy workloads still run on older Elasticsearch versions — particularly 5.x, 6.x, or 7.x — due to inertia, compatibility constraints, or lack of ownership. Once these versions exceed their standard support window, AWS begins charging an hourly Extended Support fee for each domain. These fees are often missed in cost reviews, especially in environments that are inactive but still provisioned",medium,published
CER-007692,aws,focus_database,aws-opensearch,Outdated OpenSearch Version Triggering Extended Support Charges,"Domains running outdated OpenSearch versions — particularly OpenSearch 1.x — begin to incur AWS Extended Support charges once they fall outside of the standard support period. These charges are persistent and apply even if the domain is inactive or lightly used. Many teams overlook this cost when delaying upgrades or maintaining non-critical environments like dev, test, or staging. In large organi",medium,published
CER-005883,aws,focus_storage,aws-ebs,Outdated Provisioned IOPS Volume Type for High-I/O Workloads,Many environments continue using io1 volumes for high-performance workloads due to legacy provisioning or lack of awareness of io2 benefits. io2 volumes provide equivalent or better performance and durability with reduced cost at scale. Failing to adopt io2 where appropriate results in unnecessary spend on IOPS-heavy volumes.,medium,published
CER-005213,aws,focus_database,aws-rds,Outdated RDS Cluster Incurring Extended Support Charges,"When an RDS cluster is not upgraded in time, it can fall out of standard support and incur Extended Support charges. This often happens when upgrade cycles are delayed, blocked by compatibility issues, or deprioritized due to competing initiatives. Over time, these fees can add up significantly. Staying on an outdated version also increases operational risk and reduces access to engine improvement",medium,published
CER-005308,aws,focus_database,aws-rds,Outdated RDS Versions Triggering Extended Support Charges,"Many organizations continue to run outdated database engines, such as MySQL 5.7 or PostgreSQL 11, beyond their support windows. Beginning in 2024, AWS automatically enrolls these into Extended Support to maintain security updates, adding incremental charges that scale with vCPU count. These costs often appear suddenly, impacting both production and non-production environments. For development and ",medium,published
CER-002837,azure,focus_compute,azure-virtual-machines,Outdated Virtual Machine Version in Azure,"Many organizations choose a VM SKU and version (e.g., `D4s_v3`) during the initial planning phase of a project, often based on availability, compatibility, or early cost estimates. Over time, Microsoft releases newer hardware generations (e.g., `D4s_v4`, `D4s_v5`) that offer equivalent or better performance at the same or reduced cost. However, existing VMs are not automatically migrated, and thes",medium,published
CER-009554,aws,focus_storage,aws-ebs,Outdated and Expensive EBS Volume Type,"This inefficiency occurs when legacy volume types such as gp2 or io1 remain in use, even though AWS has released newer types—like gp3 and io2—that offer better performance at lower cost. Gp3 allows users to configure IOPS and throughput independently of volume size, while io2 provides higher durability and more predictable performance than io1. These newer volumes are generally more cost-effective",medium,published
CER-003384,azure,focus_storage,azure-managed-disks,Outdated and Expensive Premium SSD Disk,"Workloads using legacy Premium SSD managed disks may be eligible for migration to Premium SSD v2, which delivers equivalent or improved performance characteristics at a lower cost. Premium SSD v2 decouples disk size from performance metrics like IOPS and throughput, enabling more granular cost optimization. Additionally, Premium SSD disks are often overprovisioned in size—for example, a P40 disk w",medium,published
CER-004741,azure,focus_storage,azure-managed-disks,Outdated and Expensive Standard SSD Disk,"Standard SSD disks can often be replaced with Premium SSD v2 disks, offering enhanced IOPS, throughput, and durability at competitive or lower pricing. For workloads that require moderate to high performance but are currently constrained by Standard SSD capabilities, migrating to Premium SSD v2 improves both performance and cost efficiency without significant operational overhead.",medium,published
CER-005855,gcp,focus_storage,gcp-gcs,Over-Retained Exported Object Versions in GCS Versioning Buckets,"When GCS object versioning is enabled, every overwrite or delete operation creates a new noncurrent version. Without a lifecycle rule to manage old versions, they persist indefinitely. Over time, this results in: * Accumulation of outdated data * Unnecessary storage costs, especially in Standard or Nearline classes * Lack of visibility into what is still needed vs. legacy debris This issue often g",medium,published
CER-007399,azure,focus_database,azure-sql,Overbilling Due to Tier Switches and Allocation Overlaps in DTU Model,"Workloads that frequently scale up and down within the same day—whether manually, via automation, or platform-managed—can encounter hidden cost amplification under the DTU model. When a database changes tiers (e.g., S7 → S4), Azure treats each tiered segment as a separate allocation and applies full-hour rounding independently. In some cases, both tiers may be billed for the same time period due t",medium,published
CER-007364,azure,focus_other,azure-monitor,Overly Frequent Querying in Azure Monitor Alerts,"While high-frequency alerting is sometimes justified for production SLAs, it's often overused across non-critical alerts or replicated blindly across environments. Projects with multiple environments (e.g., dev, QA, staging, prod) often duplicate alert rules without adjusting for business impact, which can lead to alert sprawl and inflated monitoring costs.In large-scale environments, reducing the",medium,published
CER-008388,aws,focus_other,aws-cloudwatch,Overly Permissive VPC Flow Log Filters Sent to CloudWatch Logs,"VPC Flow Logs configured with the ALL filter and delivered to CloudWatch Logs often result in unnecessarily high log ingestion volumes — especially in high-traffic environments. This setup is rarely required for day-to-day monitoring or security use cases but is commonly enabled by default or for temporary debugging and then left in place. As a result, teams incur excessive CloudWatch charges with",medium,published
CER-004858,azure,focus_database,azure-database-for-postgresql-flexible-server,Overprovisioned Azure Database for PostgreSQL Flexible Server,"Azure Database for PostgreSQL – Flexible Server often defaults to general-purpose D-series VMs, which may be oversized for many production or development workloads. PostgreSQL typically does not require a high sustained high CPU, making it well-suited to memory-optimized (E-series) or burstable (B-series) instances.When actual usage consistently falls below the provisioned capacity — particularly ",medium,published
CER-004864,azure,focus_database,azure-sql,Overprovisioned Compute Tier in Azure SQL Database,"Azure SQL Database resources are frequently overprovisioned due to default configurations, conservative sizing, or legacy requirements that no longer apply. This inefficiency appears across all deployment models:* Single Databases may be assigned more DTUs or vCores than the workload requires * Elastic Pools may be oversized for the actual demand of pooled databases * Managed Instances are often d",medium,published
CER-005151,aws,focus_storage,aws-ebs,Overprovisioned EBS Volume,"EBS volumes often remain significantly overprovisioned compared to the actual data stored on them. Because billing is based on the total provisioned capacity—not actual usage—this creates ongoing waste when large volumes are only partially used. Overprovisioning may result from default sizing in templates, misestimated requirements, or conservative provisioning practices. Identifying and remediati",medium,published
CER-004589,oci,focus_network,oci-load-balancer,Overprovisioned Load Balancer,"Load balancers incur charges based on provisioned bandwidth shape, even if backend traffic is minimal. If traffic is low, or if only one backend server is configured, the load balancer may be oversized or unnecessary, especially in test or staging environments.",medium,published
CER-005871,azure,focus_storage,azure-managed-disks,Overprovisioned Managed Disk for VM Limits,"Each Azure VM size has a defined limit for total disk IOPS and throughput. When high-performance disks (e.g., Premium SSDs with high IOPS capacity) are attached to low-tier VMs, the disk’s performance capabilities may exceed what the VM can consume. This results in paying for performance that the VM cannot access. For example, attaching a large Premium SSD to a B-series VM will not provide the exp",medium,published
CER-004631,aws,focus_compute,aws-lambda,Overprovisioned Memory Allocation for Lambda Functions,"Each Lambda function must be configured with a memory setting, which indirectly controls the amount of CPU and networking performance allocated. In many environments, memory settings are defined arbitrarily or left unchanged as functions evolve. Over time, this leads to overprovisioning — with functions running well below their allocated memory and incurring unnecessary compute costs. Systematic r",medium,published
CER-007272,gcp,focus_compute,gcp-cloud-run,Overprovisioned Memory Allocation in Cloud Run Services,"In Cloud Run, each revision is deployed with a fixed memory allocation (e.g., 512MiB, 1GiB, 2GiB, etc.). These settings are often overestimated during initial development or copied from templates. Unlike auto-scaling platforms that adapt instance size based on workload, Cloud Run continues to bill per the allocated amount regardless of actual memory used during execution. If a service consistently",medium,published
CER-007004,gcp,focus_compute,gcp-cloud-run,Overprovisioned Memory in Cloud Run Services,"Cloud Run allows users to allocate up to 8 GB of memory per container instance. If memory is overestimated — often as a buffer or based on unvalidated assumptions — customers pay for more than what the workload consumes during execution. Unlike in VM-based environments where memory might be shared or underutilized without direct cost impact, in Cloud Run, you're billed precisely for what you alloc",medium,published
CER-006165,gcp,focus_compute,gcp-gke,Overprovisioned Node Pool in GKE Cluster,"Node pools provisioned with large or specialized VMs (e.g., high-memory, GPU-enabled, or compute-optimized) can be significantly overprovisioned relative to the actual pod requirements. If workloads consistently leave a large portion of resources unused (e.g., low CPU/memory request-to-capacity ratio), the organization incurs unnecessary compute spend. This often happens in early cluster design ph",medium,published
CER-006107,azure,focus_database,azure-sql,Overprovisioned Storage in Azure SQL Elastic Pools or Managed Instances,"Azure SQL deployments often reserve more storage than needed, either due to default provisioning settings or anticipated future growth. Over time, if actual usage remains low, these oversized allocations generate unnecessary storage costs.In Elastic Pools, resizing can be done through standard configuration updates. In Managed Instances, reducing storage may require a shrink operation to reclaim u",medium,published
CER-007191,aws,focus_storage,aws-efs,Overprovisioned Throughput in EFS,"When file systems are launched with Provisioned Throughput, teams often overestimate future demand — especially in environments cloned from production or sized “just to be safe.” Over time, many workloads consume far less throughput than allocated, especially in dev/test environments or during periods of reduced usage. These overprovisioned settings can silently accrue substantial monthly charges ",medium,published
CER-005227,gcp,focus_other,gcp-pub-sub-lite,Overprovisioned Throughput in Pub/Sub Lite,"Pub/Sub Lite is a cost-effective alternative to standard Pub/Sub, but it requires explicitly provisioning throughput capacity. When publish or subscribe throughput is overestimated, customers continue to pay for unused capacity — similar to idle virtual machines or overprovisioned IOPS. This inefficiency is often found in development environments or early-stage production workloads where traffic p",medium,published
CER-009476,gcp,focus_ai,gcp-vertex-ai,Overprovisioned Vertex AI Endpoints,"Vertex AI Prediction Endpoints support autoscaling but require customers to specify a **minimum number of replicas**. These replicas stay online at all times to serve incoming traffic. When the minimum value is set too high for real traffic levels, the system maintains idle capacity that still incurs hourly charges. This inefficiency commonly arises when teams: * Use default replica settings durin",medium,published
CER-004763,aws,focus_compute,aws-lambda,Overreliance on Lambda at Sustained Scale,"Lambda is designed for simplicity and elasticity, but its pricing model becomes expensive at scale. When a function runs frequently (e.g., millions of invocations per day) or for extended durations, the cumulative cost may exceed that of continuously running infrastructure. This is especially true for predictable workloads that don’t require the dynamic scaling Lambda provides.Teams often continue",medium,published
CER-001429,azure,focus_compute,,Oversized Hosting Plan for Azure Functions,"Teams often choose the Premium or App Service Plan for Azure Functions to avoid cold start delays or enable VNET connectivity, especially early in a project when performance concerns dominate. However, these decisions are rarely revisited—even as usage patterns change.In practice, many workloads running on Premium or App Service Plans have low invocation frequency, minimal execution time, and no s",medium,published
CER-006814,aws,focus_database,aws-rds,Oversized RDS Instance Storage,"This inefficiency occurs when an RDS instance is allocated significantly more storage than it consumes. For example, a 2TB volume might contain only 150GB of actual data. Since RDS does not allow reducing allocated storage on existing instances, these volumes continue to incur charges based on total provisioned size—not actual usage. This often goes unnoticed in long-running databases that no long",medium,published
CER-002127,databricks,focus_compute,databricks-clusters,Oversized Worker or Driver Nodes in Databricks Clusters,"Databricks users can select from a wide range of instance types for cluster driver and worker nodes. Without guardrails, teams may choose high-cost configurations (e.g., 16xlarge nodes) that exceed workload requirements. This results in inflated costs with little performance benefit. To reduce this risk, administrators can use compute policies to define acceptable node types and enforce size limit",medium,published
CER-009761,databricks,focus_compute,databricks-compute,Overuse of Photon in Non-Production Workloads,"Photon is frequently enabled by default across Databricks workspaces, including for development, testing, and low-concurrency workloads. In these non-production contexts, job runtimes are typically shorter, SLAs are relaxed or nonexistent, and performance gains offer little business value.Enabling Photon in these environments can inflate DBU costs substantially without meaningful runtime improveme",medium,published
CER-005273,gcp,focus_compute,gcp-dataflow,Pipeline Breaks from Outdated Dependency Images in Dataflow,"In restricted or isolated network environments, Dataflow workers often cannot reach the public internet to download runtime dependencies. To operate securely, organizations build custom worker images that bundle required libraries. However, these images must be manually updated to keep dependencies current. As upstream packages evolve, outdated internal images can cause pipeline errors, execution ",medium,published
CER-002508,databricks,focus_compute,databricks-compute,Poorly Configured Autoscaling on Databricks Clusters,"Autoscaling is a core mechanism for aligning compute supply with workload demand, yet it's often underutilized or misconfigured. In older clusters or ad-hoc environments, autoscaling may be disabled by default or set with tight min/max worker limits that prevent scaling. This can lead to persistent overprovisioning (and wasted cost during idle periods) or underperformance due to insufficient paral",medium,published
CER-009910,azure,focus_ai,azure-cognitive-services,Provisioned Throughput OpenAI Deployment in Non-Production Environments,"PTU deployments guarantee dedicated throughput and low latency, but they also require paying for reserved capacity at all times. In non-production environments—such as dev, test, QA, or experimentation—usage patterns are typically sporadic and unpredictable. Deploying PTUs in these environments leads to consistent baseline spend without corresponding value. On-demand deployments scale usage cost w",medium,published
CER-008042,aws,focus_compute,aws-lambda,Recursive Invocation Loop Between Lambda and SQS,"When a Lambda function processes messages from an SQS queue but fails to handle certain messages properly, the same messages may be returned to the queue and retried repeatedly. In some cases, especially if the Lambda is also writing messages back to the same or a chained queue, this can create a recursive invocation loop. This loop results in high invocation counts, prolonged execution, and unnec",medium,published
CER-002439,aws,focus_compute,aws-lambda,Recursive Lambda Function Invocation,"Recursive invocation occurs when a Lambda function triggers itself directly or indirectly, often through an event source like SQS, SNS, or another Lambda. This loop can be unintentional — for example, when the function writes output to a queue it also consumes. Without controls, this can lead to runaway invocations, dramatically increasing cost with no business value.",medium,published
CER-003116,gcp,focus_other,gcp-cloud-logging,Resources Generating Excessive INFO Logs,"Some GCP services and workloads generate INFO-level logs at very high frequencies — for example, load balancers logging every HTTP request or GKE nodes logging system health messages. While valuable for debugging, these logs can flood Cloud Logging with non-critical data. Without log-level tuning or exclusion filters, organizations incur continuous ingestion charges for messages that are seldom an",medium,published
CER-005068,snowflake,focus_storage,snowflake-tables,Retention of Unused Data in Snowflake Table,"Retention of stale data occurs when old, no longer needed records are preserved within active Snowflake tables. Without lifecycle policies or regular purging, tables accumulate outdated data.Because Snowflake’s compute charges are tied to how much data is scanned, retaining large volumes of inactive or irrelevant data can drive up both storage and query execution costs unnecessarily.",medium,published
CER-002606,azure,focus_storage,azure-storage-account,SFTP Feature Enabled on Azure Storage Account Without Usage,"Azure users may enable the SFTP feature on Storage Accounts during migration tests, integration scenarios, or experimentation. However, if left enabled after initial use, the feature continues to generate flat hourly charges — even when no SFTP traffic occurs.Because this fee is incurred silently and independently of storage usage, it often goes unnoticed in cost reviews. When SFTP is not actively",medium,published
CER-008679,aws,focus_compute,aws-ec2,Stale Dedicated Hosts for Stopped EC2 Mac Instances,"When an EC2 Mac instance is stopped or terminated, its associated dedicated host remains allocated by default. Because Mac instances are the only EC2 type billed at the host level, charges continue to accrue as long as the host is retained. This can lead to significant waste when: * Instances are stopped but the host is never released * Hosts are retained unintentionally after workloads are migrat",medium,published
CER-005906,aws,focus_compute,aws-appstream-2-0,Suboptimal AppStream Fleet Auto Scaling Policies,When fleet auto scaling policies maintain more active instances than are required to support current usage—particularly during off-peak hours—organizations incur unnecessary compute costs. Fleets often remain oversized due to conservative default configurations or lack of schedule-based scaling. Tuning the scaling policies to better reflect usage patterns ensures that streaming infrastructure alig,medium,published
CER-003004,aws,focus_compute,aws-lambda,Suboptimal Architecture Configuration for Lambda Functions,"While many AWS customers have migrated EC2 workloads to Graviton to reduce costs, Lambda functions often remain on the default x86 architecture. AWS Graviton2 (ARM) offers lower pricing and equal or better performance for most supported runtimes — yet adoption remains uneven due to legacy defaults or lack of awareness. Continuing to run eligible Lambda functions on x86 leads to unnecessary spendin",medium,published
CER-003629,azure,focus_compute,azure-virtual-machines,Suboptimal Architecture Selection for Azure Virtual Machines,"Azure provides VM families across three major CPU architectures, but default provisioning often leans toward Intel-based SKUs due to inertia or pre-configured templates. AMD and ARM alternatives offer substantial cost savings; ARM in particular can be 30–50% cheaper for general-purpose workloads. These price differences accumulate quickly at scale.ARM-based VMs in Azure (e.g., Dps_v5, Eps_v5) are ",medium,published
CER-006743,aws,focus_compute,aws-fargate,Suboptimal Architecture Selection in AWS Fargate,"AWS Fargate supports both x86 and Graviton2 (ARM64) CPU architectures, but by default, many workloads continue to run on x86. Graviton2 delivers significantly better price-performance, especially for stateless, scale-out container workloads. Teams that fail to configure task definitions with the `ARM64` architecture miss out on meaningful efficiency gains. Because this setting is not enabled autom",medium,published
CER-008052,aws,focus_compute,aws-lambda,Suboptimal Architecture Selection in AWS Lambda,"Lambda functions default to the x86\_64 architecture, which is more expensive than Arm64. For many workloads, especially those written in interpreted languages (e.g., Python, Node.js) or compiled to architecture-neutral bytecode (e.g., Java), there is no dependency on x86-specific binaries. In such cases, moving to Arm64 can reduce compute costs by 20% without impacting functionality. Despite this",medium,published
CER-004754,azure,focus_ai,azure-cognitive-services,Suboptimal Azure OpenAI Model Type,"Azure releases newer OpenAI models that provide better performance and cost characteristics compared to older generations. When workloads remain on outdated model versions, they may consume more tokens to produce equivalent output, run slower, or miss out on quality improvements. Because customers pay per token, using an older model can lead to unnecessary spending and reduced value. Aligning depl",medium,published
CER-001382,aws,focus_ai,aws-bedrock,Suboptimal Bedrock Custom Model,"Teams often start custom-model deployments with large architectures, full-precision weights, or older model versions carried over from training environments. When these models transition to Bedrock’s managed inference environment, the compute footprint (especially GPU class) becomes a major cost driver. Common inefficiencies include: * Deploying outdated custom models despite newer, more efficient",medium,published
CER-001937,aws,focus_ai,aws-bedrock,Suboptimal Bedrock Inference Profile Model,"AWS frequently updates Bedrock with improved foundation models, offering higher quality and better cost efficiency. When workloads remain tied to older model versions, token consumption may increase, latency may be higher, and output quality may be lower. Using outdated models leads to avoidable operational costs, particularly for applications with consistent or high-volume inference activity. Reg",medium,published
CER-004616,aws,focus_ai,aws-bedrock,Suboptimal Bedrock Model Type,"Bedrock’s model catalog evolves quickly as providers release new versions—such as successive Claude model families or updated Amazon Titan models. These newer models frequently offer improved performance, more efficient reasoning, better context handling, and higher-quality outputs compared to older generations. When workloads continue using older or deprecated models, they may require **more toke",medium,published
CER-002825,azure,focus_ai,azure-cognitive-services,Suboptimal Cache Usage for Repetitive Azure OpenAI Workloads,"A large share of production AI workloads include repetitive or static requests—such as classification labels, routing decisions, FAQ responses, metadata extraction, or deterministic prompt templates. Without a caching layer, every repeated request is sent to the model, incurring full token charges and increasing latency. Azure OpenAI does not provide native caching, so teams must implement caching",medium,published
CER-007300,aws,focus_ai,aws-bedrock,Suboptimal Cache Usage for Repetitive Bedrock Inference Workloads,"Bedrock workloads commonly include repetitive inference patterns—such as classification results, prompt templates generating deterministic outputs, FAQ responses, document tagging, and other predictable or low-variability tasks. Without a caching strategy (API-layer cache, application cache, or hash-based prompt cache), these workloads repeatedly invoke the model and incur token costs for answers ",medium,published
CER-009521,gcp,focus_ai,gcp-vertex-ai,Suboptimal Cache Usage for Repetitive Inference,"A large portion of real-world AI workloads involve repetitive or deterministic inference patterns—such as classification labels, routing logic, metadata extraction, FAQ responses, keyword detection, or summarization of static content. Vertex AI does **not** provide native inference caching, so applications that repeatedly send identical prompts to the model incur avoidable cost. When no caching me",medium,published
CER-003832,aws,focus_network,aws-cloudfront,Suboptimal Configuration of a CloudFront Distribution,"This inefficiency occurs when compression is either disabled or not functioning effectively on a CloudFront distribution. Static assets such as text, JSON, JavaScript, and CSS files are compressible and benefit significantly from compression. Without compression, CloudFront transfers larger objects, leading to increased data transfer charges and slower delivery performance—without improving user e",medium,published
CER-009673,aws,focus_network,aws-nat-gateway,Suboptimal Cross-AZ Routing to NAT Gateway,"NAT Gateways are designed to serve private subnets within the same Availability Zone. When subnets in one AZ are configured to route traffic through a NAT Gateway in a different AZ, the traffic crosses AZ boundaries and incurs inter-AZ data transfer charges in addition to the standard NAT processing fees.This typically happens when:* NAT Gateways are deployed in multiple AZs (as recommended for re",medium,published
CER-004833,aws,focus_database,aws-elasticache,Suboptimal ElastiCache Engine Selection,"Many workloads default to using Redis or Memcached without evaluating whether a lighter or more efficient engine would provide equivalent functionality at lower cost. Valkey is a Redis-compatible, open-source engine supported by ElastiCache that may offer improved price-performance and licensing benefits. For read-heavy or stateless workloads that don’t require Redis-specific features (e.g., persi",medium,published
CER-008704,aws,focus_database,aws-memorydb,Suboptimal Engine Selection in MemoryDB,"MemoryDB now supports Valkey, a drop-in replacement for Redis OSS offering significant cost and performance advantages. However, many deployments still default to Redis OSS, incurring higher hourly costs and unnecessary data write charges. For compatible workloads, continuing to use Redis OSS instead of Valkey represents a missed opportunity for savings and modernization.",medium,published
CER-005332,azure,focus_compute,azure-data-factory-v2,Suboptimal Integration Runtime Region Selection in Azure Data Factory,"When Integration Runtimes are configured with the default “Auto Resolve” region setting, Azure may automatically provision them in a region different from the data sources or sinks. For example, an environment deployed in West Europe may run pipelines in US East. This causes unnecessary cross-region data transfer, increasing networking costs and pipeline latency. The inefficiency often goes unnoti",medium,published
CER-002907,aws,focus_storage,aws-s3,Suboptimal Lifecycle Policy for Small Files on an S3 Bucket,"This inefficiency occurs when small files are stored in S3 storage classes that impose a minimum object size charge, resulting in unnecessary costs. Small files under 128 KB stored in Glacier Instant Retrieval, Standard-IA, or One Zone-IA are billed as if they were 128 KB. If these small files are accessed frequently, S3 Standard may be a better fit. For infrequently accessed small files, transiti",medium,published
CER-004339,azure,focus_network,azure-load-balancer,Suboptimal Load Balancer Rule Configuration in Azure Standard Load Balancer,"As organizations migrate from the Basic to the Standard tier of Azure Load Balancer (driven by Microsoft’s retirement of the Basic tier), they may unknowingly inherit cost structures they didn’t previously face. Specifically, each load balancing rule—both inbound and outbound—can contribute to ongoing charges. In applications that historically relied only on Basic load balancers, outbound rules ma",medium,published
CER-002627,aws,focus_other,aws-cloudwatch,Suboptimal Log Class Configuration in CloudWatch,"By default, CloudWatch Log Groups use the Standard log class, which applies higher rates for both ingestion and storage. AWS also offers an Infrequent Access (IA) log class designed for logs that are rarely queried — such as audit trails, debugging output, or compliance records. Many teams assume storage is the dominant cost driver in CloudWatch, but in high-volume environments, ingestion costs ca",medium,published
CER-007527,aws,focus_compute,aws-eks,Suboptimal Memory-to-CPU Ratio in EKS Cluster Node,"When the EC2 instance types used for EKS node groups have a memory-to-CPU ratio that doesn’t match the workload profile, the result is poor bin-packing efficiency. For example, if memory-intensive containers are scheduled on compute-optimized nodes, memory may run out first while CPU remains unused. This forces new nodes to be provisioned earlier than necessary. Over time, this mismatch can lead t",medium,published
CER-006849,snowflake,focus_other,snowflake-query-processing,Suboptimal Query Routing,"Organizations may experience unnecessary Snowflake spend due to inefficient query-to-warehouse routing, lack of dynamic warehouse scaling, or failure to consolidate workloads during low-usage periods. Third-party platforms offer solutions to address these inefficiencies: Sundeck enables highly customizable, SQL-based control over the query lifecycle through user-defined rules (Flows, Hooks, Condit",medium,published
CER-003317,snowflake,focus_compute,snowflake-virtual-warehouse,Suboptimal Query Timeout Configuration,"If no appropriate query timeout is configured, inefficient or runaway queries can execute for extended periods (up to the default 2-day system limit). For as long as the query is running, the warehouse will remain active and accrue costs. Proper timeout settings help terminate inefficient queries, free up compute capacity, and allow the warehouse to become idle sooner, making it eligible for auto-",medium,published
CER-003695,aws,focus_database,aws-rds,Suboptimal RDS Instance Storage Type,"This inefficiency occurs when an RDS instance uses a high-cost storage type such as io1 or io2 but does not require the performance benefits it provides. In many cases, provisioned IOPS are set at or below the free baseline included with gp3 (3,000 IOPS and 125 MB/s). In such scenarios, continuing to use provisioned IOPS storage results in elevated cost with no functional advantage. These misconfi",medium,published
CER-009154,aws,focus_compute,aws-ec2,Suboptimal Region for EC2 Instance,"Workloads are sometimes deployed in specific AWS regions based on legacy decisions, developer convenience, or perceived performance requirements. However, regional EC2 pricing can vary significantly, and placing instances in a suboptimal region can lead to higher compute costs, increased data transfer charges, or both. In particular, workloads that frequently communicate with resources in other re",medium,published
CER-001072,aws,focus_compute,aws-ec2,Suboptimal Region for Internet-Only EC2 Instance,"When an EC2 instance is dedicated primarily to internet-facing traffic, regional differences in data transfer pricing can drive a substantial portion of total costs. Hosting such workloads in a region with higher egress rates leads to elevated expenses without improving performance. Migrating the workload to a lower-cost region can yield significant savings while maintaining equivalent service qua",medium,published
CER-003847,aws,focus_network,aws-nat-gateway,Suboptimal Routing Through NAT Gateway Instead of VPC Endpoint,"Workloads in private subnets often access AWS services like S3 or DynamoDB. If this traffic is routed through a NAT Gateway, it incurs both hourly and data processing charges. However, AWS offers VPC Gateway Endpoints (for S3/DynamoDB) and Interface Endpoints (for other services), which provide private access paths that bypass the NAT Gateway entirely. When teams fail to use VPC endpoints — often ",medium,published
CER-003877,aws,focus_database,aws-aurora,Suboptimal Storage Configuration for Aurora Cluster,"Many Aurora clusters default to using the Standard configuration, which charges separately for I/O operations. For workloads with frequent read and write activity, this can lead to unnecessarily high costs. Aurora I/O-Optimized eliminates I/O charges entirely and simplifies cost predictability. In environments with consistently high I/O usage, switching to I/O-Optimized often results in lower tota",medium,published
CER-003316,aws,focus_database,aws-dynamodb,Suboptimal Storage Type for DynamoDB Table,"This inefficiency occurs when a table remains in the default Standard storage class despite having minimal or infrequent access. In these cases, switching to Standard-IA can significantly reduce monthly storage costs, especially for archival tables, compliance data, or legacy systems that are still retained but rarely queried.",medium,published
CER-008973,gcp,focus_other,gcp-cloud-logging,Suboptimal Storage for Logs,"Many organizations retain all logs in Cloud Logging’s standard storage, even when the data is rarely queried or required only for audit or compliance. Logging buckets are priced for active access and are not optimized for low-frequency retrievas, results in unnecessary expense. Redirecting logs to BigQuery or Cloud Storage can provide better cost efficiency, particularly when coupled with lifecycl",medium,published
CER-003505,azure,focus_other,log-analytics,Suboptimal Table Plan Selection in Log Analytics,"By default, all Log Analytics tables are created under the Analytics plan, which is optimized for high-performance querying and interactive analysis. However, not all telemetry requires real-time access or frequent querying. Some tables may serve audit, archival, or compliance use cases where querying is rare or unnecessary. Leaving such tables on the Analytics plan results in unnecessary spend—es",medium,published
CER-001942,aws,focus_compute,aws-ec2,Suboptimal Use of Compute Savings Plans for Specialized Instances,"Accelerated EC2 instance types such as `p5.48xlarge` and `p5en.48xlarge (often used for ML/AI workloads)` are eligible for Compute Savings Plans, but the discount rates offered are modest compared to more common instance families. When organizations rely solely on CSPs, these lower priority instances are typically the last to benefit from the plan, especially if other instance types consume most o",medium,published
CER-009239,aws,focus_storage,aws-efs,Suboptimal Use of EFS Storage Classes,"Many organizations default to storing all EFS data in the Standard class, regardless of how frequently data is accessed. This results in inefficient spend for workloads with significant portions of data that are rarely read. EFS IA and Archive tiers offer lower-cost alternatives for data with low or near-zero access, while Intelligent Tiering can automate placement decisions. Failing to leverage t",medium,published
CER-004626,aws,focus_other,aws-opensearch,Suboptimal Use of Intel-Based Instances in OpenSearch,"AWS Graviton processors are designed to deliver better price-performance than comparable Intel-based instances, often reducing cost by 20–30% at equivalent workload performance. OpenSearch domains running on older Intel-based families consume more spend without providing additional capability. Since Graviton-powered instance types are functionally identical in features and performance for OpenSear",medium,published
CER-009822,aws,focus_compute,aws-ec2,Suboptimal Use of On-Demand Instances in Fault-Tolerant EC2 Workloads,"Many EC2 workloads—such as development environments, test jobs, stateless services, and data processing pipelines—can tolerate interruptions and do not require the reliability of On-Demand pricing. Using On-Demand instances in these scenarios drives up cost without adding value. Spot Instances offer significantly lower pricing and are well-suited to workloads that can handle restarts, retries, or ",medium,published
CER-009445,databricks,focus_compute,databricks-clusters,Suboptimal Use of On-Demand Instances in Non-Production Clusters,"In Databricks, on-demand instances provide reliable performance but come at a premium cost. For non-production workloads—such as development, testing, or exploratory analysis—high availability is often unnecessary. Spot instances provide equivalent performance at a lower price, with the tradeoff of occasional interruptions. If teams default to on-demand usage in lower environments, they may be inc",medium,published
CER-006203,aws,focus_compute,aws-eks,Suboptimal Use of On-Demand Instances in a Non-Production EKS Cluster,"Running non-production clusters solely on On-Demand Instances results in unnecessarily high compute costs. Development, testing, and QA environments typically tolerate interruptions and do not require the continuous availability guaranteed by On-Demand capacity. Introducing Spot-backed node groups in non-production environments can significantly reduce infrastructure expenses without compromising ",medium,published
CER-002345,azure,focus_database,azure-sql,Suboptimal Use of Provisioned Compute for Azure SQL Database,"Databases deployed on Provisioned compute incur continuous hourly charges even when workload demand is low. For databases that are active only briefly within an hour, or for limited hours per month, Serverless can provide significantly lower cost because it bills only for active compute time. The economic break-even point between Provisioned and Serverless depends on workload activity patterns. If",medium,published
CER-001052,snowflake,focus_other,snowflake-search-optimization-service,Suboptimal Use of Search Optimization Service,"Search Optimization can enable significant cost savings when selectively applied to workloads that heavily rely on point-lookup queries. By improving lookup efficiency, it allows smaller warehouses to satisfy performance SLAs, reducing credit consumption.However, inefficiencies arise when: Search Optimization is not enabled on critical lookup-heavy tables, forcing oversized warehouses. It is enabl",medium,published
CER-006502,azure,focus_database,azure-sql,Suboptimal Use of Serverless Compute for Azure SQL Database,"Serverless is attractive for variable or idle workloads, but it can become more expensive than Provisioned compute when database activity is high for long portions of the day. As active time increases, per-second compute accumulation approaches—or exceeds—the fixed monthly cost of a Provisioned tier. This inefficiency arises when teams adopt Serverless as a default without assessing workload patte",medium,published
CER-005949,gcp,focus_ai,gcp-vertex-ai,Suboptimal Vertex Model Type,"Vertex AI model families evolve rapidly. New model versions (e.g., transitions within the Gemini family) frequently introduce improvements in efficiency, quality, and capability. When workloads continue using older, legacy, or deprecated models, they may consume more tokens, produce lower-quality results, or experience higher latency than necessary. Because generative workloads often scale quickly",medium,published
CER-007798,snowflake,focus_compute,snowflake-virtual-warehouse,Suboptimal Warehouse Auto-Suspend Configuration,"If auto-suspend settings are too high, warehouses can sit idle and continue accruing unnecessary charges. Tightening the auto-suspend window ensures that the warehouse shuts down quickly once queries complete, minimizing credit waste while maintaining acceptable user experience (e.g., caching needs, interactive performance).",medium,published
CER-002803,azure,focus_other,azure-marketplace,Transactable vs. Non-Transactable Confusion in Azure Marketplace,"Azure Marketplace offers two types of listings: transactable and non-transactable. Only transactable purchases contribute toward a customer’s MACC commitment. However, many teams mistakenly assume that all Marketplace spend counts, leading to missed opportunities to burn down commitments and risking budget inefficiencies. Selecting a non-transactable listing, when a transactable equivalent exists,",medium,published
CER-006624,aws,focus_storage,aws-ebs,Unaccessed EBS Snapshot,"This inefficiency arises when snapshots are retained long after they’ve served their purpose. Snapshots may have been created for backups, migrations, or disaster recovery plans but were never deleted—even after the related workload or volume was decommissioned. Over time, these unused snapshots accumulate, continuing to incur storage costs without providing operational value.",medium,published
CER-005466,aws,focus_storage,aws-ebs,Unarchived Long-Term EBS Snapshots,"EBS Snapshot Archive is a lower-cost storage tier for rarely accessed snapshots retained for compliance, regulatory, or long-term backup purposes. Archiving snapshots that do not require frequent or fast retrieval can reduce snapshot storage costs by up to 75%. Despite this, many organizations retain large volumes of snapshots in the standard tier long after their operational value has expired.",medium,published
CER-002639,azure,focus_network,aws-vpc,Unassigned Public IP Address,"In Azure, it’s common for public IP addresses to be created as part of virtual machine or load balancer configurations. When those resources are deleted or reconfigured, the IP address may remain in the environment unassigned. While Basic SKUs are free when idle, Standard SKUs incur ongoing hourly charges, even if the address is not in use.Unassigned Standard public IPs provide no functional value",medium,published
CER-009876,aws,focus_network,aws-eip,Unassociated Elastic IP Address,"Elastic IPs are often provisioned but forgotten — left unassociated, or still attached to EC2 instances that have been stopped. In either case, AWS treats the EIP as idle and applies an hourly charge. Although the cost per hour is relatively small, these charges accumulate quietly, especially across environments with frequent provisioning, decommissioning, or ephemeral workloads. Many organization",medium,published
CER-009625,oci,focus_storage,oci-block-volume,Unattached Block Volume (Non-Boot),"Block volumes that are not attached to any instance continue to incur charges. These often accumulate after instance deletion or reconfiguration. Unlike boot volumes, unattached data volumes may be harder to track if not labeled or tagged clearly.",medium,published
CER-008416,oci,focus_storage,oci-block-volume,Unattached Boot Volume,"When a Compute instance is terminated in OCI, the associated boot volume is not deleted by default. If the termination settings don’t explicitly delete the boot volume, it persists and continues to generate storage charges. Because boot volumes are managed under the Block Volumes service, not within the Compute UI, they’re easy to overlook—especially in environments with frequent provisioning and ",medium,published
CER-005364,aws,focus_compute,aws-ec2,Unconverted Convertible EC2 Reserved Instances,"Convertible Reserved Instances provide valuable pricing flexibility — but that flexibility is often underused. When EC2 workloads shift across instance families or OS types, the original RI may no longer apply to active usage. If the RI is not converted, the customer continues paying for unused commitment despite having the ability to adapt it.Because conversion is a manual process and requires ma",medium,published
CER-004468,aws,focus_compute,aws-fargate,Underuse of Fargate Spot for Interruptible Workloads,"Many teams run workloads on standard Fargate pricing even when the workload is fault-tolerant and could tolerate interruptions. Fargate Spot provides the same performance characteristics at up to 70% lower cost, making it ideal for stateless jobs, batch processing, CI/CD runners, or retry-friendly microservices.",medium,published
CER-007020,databricks,focus_compute,databricks-serverless-compute,Underuse of Serverless Compute for Jobs and Notebooks,"Databricks Serverless Compute is now available for jobs and notebooks, offering a simplified, autoscaled compute environment that eliminates cluster provisioning, reduces idle overhead, and improves Spot survivability. For short-running, bursty, or interactive workloads, Serverless can significantly reduce cost by billing only for execution time. However, Serverless is not universally available or",medium,published
CER-001684,databricks,focus_compute,databricks-sql,Underuse of Serverless for Short or Interactive Workloads,"Many organizations continue running short-lived or low-intensity SQL workloads — such as dashboards, exploratory queries, and BI tool integrations — on traditional clusters. This leads to idle compute, overprovisioning, and high baseline costs, especially when the clusters are always-on. Databricks SQL Serverless is optimized for bursty, interactive use cases with auto-scaling and pay-per-second p",medium,published
CER-001935,azure,focus_compute,azure-reservations,Underutilized Azure Reserved Instance Due to Workload Drift,"As workloads evolve, Azure Reserved Instances (RIs) may no longer align with actual usage — due to refactoring, region changes, autoscaling, or instance-type drift. When this happens, the committed usage goes unused, while new workloads run on non-covered SKUs, resulting in both underutilized reservations and full-price on-demand charges elsewhere.The root inefficiency is architectural or operatio",medium,published
CER-002591,azure,focus_compute,azure-virtual-machines,Underutilized Azure Virtual Machine,"Azure VMs are frequently provisioned with more vCPU and memory than needed, often based on template defaults or peak demand assumptions. When a VM operates well below its capacity for an extended period, it presents an opportunity to reduce costs through rightsizing. Without regular usage reviews, these inefficiencies can persist indefinitely.",medium,published
CER-006090,gcp,focus_database,gcp-cloud-sql,Underutilized Cloud SQL Instance,"Cloud SQL instances are often over-provisioned or left running despite low utilization. Since billing is based on allocated vCPUs, memory, and storage — not usage — any misalignment between actual workload needs and provisioned capacity leads to unnecessary spend. Common causes include: * Initial oversizing during launch that was never revisited * Non-production environments with continuous uptime",medium,published
CER-003956,oci,focus_compute,oci-compute-instances,Underutilized Compute Instance,"OCI Compute instances incur cost based on provisioned CPU and memory, even when the instance is lightly loaded. Instances that show consistently low usage across time, such as those used only for occasional tasks, test environments, or forgotten workloads, may be overprovisioned relative to their actual needs.",medium,published
CER-007851,aws,focus_compute,aws-ec2,Underutilized EC2 Commitment Due to Workload Drift,"When EC2 usage declines, shifts to different instance families, or moves to other services (e.g., containers or serverless), organizations may find that previously purchased Standard Reserved Instances or Savings Plans no longer match current workload patterns.This misalignment results in underutilized commitments—where costs are still incurred, but no usage is benefiting from the associated disco",medium,published
CER-005349,aws,focus_compute,aws-ec2,Underutilized EC2 Instance,"EC2 instances are often overprovisioned based on rough estimates, legacy patterns, or performance buffer assumptions. If an instance consistently uses only a small fraction of its provisioned CPU or memory, it likely represents an opportunity for rightsizing. These inefficiencies persist unless usage is periodically reviewed and instance types are adjusted to align with actual workload requirement",medium,published
CER-005361,aws,focus_database,aws-elasticache,Underutilized ElastiCache Node,"ElastiCache clusters are often sized for peak performance or reliability assumptions that no longer reflect current workload needs. When memory and CPU usage remain consistently low, the node is likely overprovisioned. For Redis, memory is typically the primary sizing constraint, while Memcached workloads may be more CPU-sensitive. In dev, staging, or lightly used production environments, some nod",medium,published
CER-008681,gcp,focus_compute,gcp-compute-engine,Underutilized GCP VM Instance,"GCP VM instances are often provisioned with more CPU or memory than needed, especially when using custom machine types or legacy templates. If an instance consistently consumes only a small portion of its allocated resources, it likely represents an opportunity to reduce costs through rightsizing. Without proactive reviews, these oversized instances can remain unnoticed and continue to incur unnec",medium,published
CER-002207,aws,focus_compute,aws-ec2,Underutilized Instances in EC2 Auto Scaling Group,"Oversized instances within Auto Scaling Groups lead to inflated baseline costs, even when scaling adjusts the number of instances dynamically. When workloads consistently use only a fraction of the available CPU, memory, or network capacity, there is an opportunity to downsize to smaller, less expensive instance types without sacrificing performance. Right-sizing helps balance capacity and efficie",medium,published
CER-004579,aws,focus_compute,aws-eks,Underutilized Kubernetes Workload,"When Kubernetes workloads request more CPU and memory than they actually consume, nodes must reserve capacity that remains unused. This leads to lower node density, forcing the cluster to maintain more instances than necessary. Aligning resource requests with observed utilization improves cluster efficiency and reduces compute spend without sacrificing application performance.",medium,published
CER-009295,azure,focus_ai,azure-cognitive-services,Underutilized PTU Quota for Azure OpenAI Deployments,"When organizations size PTU capacity based on peak expectations or early traffic projections, they often end up with more throughput than regularly required. If real-world usage plateaus below provisioned levels, a portion of the PTU capacity remains idle but still generates full spend each hour. This is especially common shortly after production launch or during adoption of newer GPT-4 class mode",medium,published
CER-004756,aws,focus_storage,aws-ebs,Underutilized Provisioned IOPS on an EBS Volume,"This inefficiency occurs when an EBS volume has provisioned IOPS levels that consistently exceed the actual I/O requirements of the workload it supports. This can happen when performance buffers are estimated too high, usage patterns change over time, or default settings are left unadjusted. Provisioned IOPS above the included baseline generate ongoing charges that may not reflect actual utilizati",medium,published
CER-008986,aws,focus_database,aws-rds,Underutilized RDS Commitment Due to Workload Drift,"RDS workloads often evolve — changing engine types, rightsizing instances, or shifting to Aurora or serverless models. When these changes occur after Reserved Instances have been purchased, the existing commitments may no longer match active usage. This results in silent overspend, as underutilized RIs continue billing without offsetting usage.Unlike Convertible EC2 RIs, RDS RIs cannot be exchange",medium,published
CER-005711,aws,focus_database,aws-rds,Underutilized RDS Instance,"This inefficiency occurs when an RDS instance is consistently operating below its provisioned capacity—for example, showing low CPU, or memory utilization over an extended period. This often results from conservative initial sizing, decreased workload demand, or failure to review and adjust after deployment. Running oversized RDS instances leads to unnecessary compute and licensing costs without d",medium,published
CER-009307,aws,focus_database,aws-dynamodb,Underutilized Read Capacity on a DynamoDB Table,"Provisioned capacity mode is appropriate for workloads with consistent or predictable throughput. However, when read capacity is significantly over-provisioned relative to actual usage, it results in wasted spend. This inefficiency is especially common in dev/test environments, legacy systems, or workloads that have tapered off over time but were never adjusted.",medium,published
CER-004130,snowflake,focus_compute,snowflake-virtual-warehouse,Underutilized Snowflake Warehouse,"Underutilized Snowflake warehouses occur when a workload is assigned a larger warehouse size than necessary. For example, a workload that could efficiently execute on a Medium (M) warehouse may be running on a Large (L) or Extra Large (XL) warehouse.This leads to unnecessary credit consumption without a proportional benefit to performance. Underutilization is often driven by early provisioning dec",medium,published
CER-009150,gcp,focus_compute,gcp-compute-engine,Underutilized VM Commitments Due to Architectural Drift,"VM-based Committed Use Discounts in GCP offer cost savings for predictable workloads, but they are rigid: they apply only to specified VM types, quantities, and regions. When organizations evolve their architecture — such as moving to GKE (Kubernetes), Cloud Run, or autoscaling — usage patterns often shift away from the original commitments. Because GCP lacks flexible reallocation options like AWS",medium,published
CER-007946,aws,focus_database,aws-dynamodb,Underutilized Write Capacity on a DynamoDB Table,"Provisioned capacity mode is appropriate for workloads with consistent or predictable throughput. However, when write capacity is significantly over-provisioned relative to actual usage, it results in wasted spend. This inefficiency is especially common in dev/test environments, legacy systems, or workloads that have tapered off over time but were never adjusted.",medium,published
CER-008856,aws,focus_compute,aws-appstream-2-0,Underutilized or Overprovisioned AppStream Instances,"AppStream fleets often default to instance types designed for worst-case or peak usage scenarios, even when average workloads are significantly lighter. This leads to consistently low utilization of CPU, memory, or GPU resources and inflated infrastructure costs. By right-sizing AppStream instances based on actual workload needs, organizations can reduce spend without compromising user experience.",medium,published
CER-001232,aws,focus_storage,aws-s3,Unexpired Non-Current Object Versions in S3,"When S3 versioning is enabled but no lifecycle rules are defined for non-current objects, outdated versions accumulate indefinitely. These non-current versions are rarely accessed but continue to incur storage charges. Over time, this leads to significant hidden costs, particularly in buckets with frequent object updates or automated data pipelines. Proper lifecycle management is required to limit",medium,published
CER-001153,aws,focus_other,aws-config,Unfiltered Recording of High-Churn Resource Types in AWS Config,"By default, AWS Config can be set to record changes across all supported resource types, including those that change frequently, such as security group rules, IAM role policies, route tables, or network interfaces frequent ephemeral resources in containerized or auto-scaling setupsThese high-churn resources can generate an outsized number of configuration items and inflate costs — especially in dy",medium,published
CER-001877,aws,focus_compute,aws-athena,Unmanaged Growth of Athena Query Output Buckets,"Athena generates a new S3 object for every query result, regardless of whether the output is needed long term. Over time, this leads to uncontrolled growth of the output bucket, especially in environments with repetitive queries such as cost and usage reporting. Many of these files are transient and provide little value once the query is consumed. Without lifecycle rules, organizations pay for unn",medium,published
CER-001361,aws,focus_other,aws-config,Unnecessarily High Recording Granularity in AWS Config,"Organizations frequently inherit continuous recording by default (e.g., through landing zones) without validating the business need for per-change granularity across all resource types and environments. In change-heavy accounts (ephemeral resources, CI/CD churn, autoscaling), continuous mode drives very high CIR volumes with limited additional operational value. Selecting periodic recording for lo",medium,published
CER-005995,aws,focus_compute,aws-lambda,Unnecessary Costs from Unused Lambda Versions with SnapStart,"Many teams publish new Lambda versions frequently (e.g., through CI/CD pipelines) but do not clean up old ones. When SnapStart is enabled, each of these versions retains an active snapshot in the cache, generating ongoing charges. Over time, accumulated unused versions can significantly increase spend without delivering any business value. This problem compounds in environments with high deploymen",medium,published
CER-007529,datadog,focus_other,datadog-logs,Unnecessary Default Log Retention in Datadog,"Many organizations keep Datadog’s default log retention settings without evaluating business requirements. Defaults may extend retention far beyond what is useful for troubleshooting, performance monitoring, or compliance. This leads to unnecessary storage and indexing costs, particularly in non-production environments or for logs with limited value after a short period. By adjusting retention per",medium,published
CER-002018,aws,focus_database,aws-rds,Unnecessary Multi-AZ Configuration for Non-Production RDS Instances,"RDS Multi-AZ deployments are designed for production-grade fault tolerance. In non-production environments, this configuration doubles the cost of database instances and storage with little added value. Unless explicitly required for high-availability testing, Multi-AZ in dev, staging, or test environments typically results in avoidable expense.",medium,published
CER-003385,aws,focus_database,aws-elasticache,Unnecessary Multi-AZ Deployment for ElastiCache in Non-Production Environments,"In non-production environments, enabling Multi-AZ Redis clusters introduces redundant replicas that may not deliver meaningful business value. These replicas are often kept in sync across Availability Zones, incurring both compute and inter-AZ data transfer costs. For development or test clusters that can tolerate occasional downtime or data loss, a single-AZ deployment is typically sufficient and",medium,published
CER-006547,aws,focus_compute,aws-ec2,Unnecessary Multi-AZ Deployment for Non-Production EC2 Instances,"Multi-AZ deployment is often essential for production workloads, but its use in non-production environments (e.g., development, test, QA) offers minimal value. These environments typically do not require high availability, yet still incur the full cost of redundant compute, storage, and data transfer. This results in unnecessary spend without operational benefit.",medium,published
CER-009580,aws,focus_database,aws-opensearch,Unnecessary Multi-AZ Deployment for OpenSearch in Non-Production Environments,"Non-production OpenSearch domains often inherit Multi-AZ configurations from production setups without clear justification. This leads to redundant replica shards across AZs, inflating both compute and storage costs. Unless strict uptime or fault tolerance requirements exist, most dev/test workloads do not benefit from Multi-AZ redundancy.",medium,published
CER-004691,gcp,focus_database,gcp-bigquery,Unnecessary Reset of Long-Term Storage Pricing in BigQuery,"BigQuery incentivizes efficient data retention by cutting storage costs in half for tables or partitions that go 90 days without modification. However, many teams unintentionally forfeit this discount by performing broad or unnecessary updates to long-lived datasets — for example, touching an entire table when only a few rows need to change. Even small-scale or programmatic updates can trigger a f",medium,published
CER-004714,databricks,focus_ai,databricks-vector-search,Unnecessary Use of Embeddings for Simple Retrieval Tasks,"Embedding-based retrieval enables semantic matching even when keywords differ. But many Databricks workloads—catalog lookups, metadata search, deterministic classification, or fixed-rule routing—do not require semantic understanding. When embeddings are used anyway, teams incur DBU cost for embedding generation, additional storage for vector columns or indexes, and more expensive similarity-search",medium,published
CER-009914,aws,focus_ai,aws-bedrock,Unnecessary Use of Embeddings for Simple Retrieval Tasks,"Embeddings enable semantic search by converting text into vectors that capture meaning. Keyword or metadata search performs exact or simple lexical matches. Many workloads—FAQ lookup, helpdesk routing, short product lookups, or rule-based filtering—do not benefit from semantic search. When embeddings are used anyway, organizations pay for embedding generation, vector storage, and similarity search",medium,published
CER-009915,snowflake,focus_ai,snowflake-cortex,Unnecessary Use of Embeddings for Simple Retrieval Tasks,"Embeddings enable semantic similarity search by representing text as high-dimensional vectors. Keyword search, however, returns results based on lexical matches and is often sufficient for simple retrieval tasks such as FAQ matching, deterministic filtering, metadata lookup, or rule-based routing. When embeddings are used for these low-complexity scenarios, organizations pay for compute to generat",medium,published
CER-009916,azure,focus_ai,azure-cognitive-services,Unnecessary Use of Embeddings for Simple Retrieval Tasks,"Embeddings enable semantic retrieval by capturing the meaning of text, while keyword search returns results based on exact or lexical matches. Many Azure workloads—FAQ search, routing, deterministic classification, or structured lookups—achieve the same or better accuracy using simple keyword or metadata filtering. When embeddings are used for these uncomplicated tasks, organizations pay for token",medium,published
CER-009917,gcp,focus_ai,gcp-vertex-ai,Unnecessary Use of Embeddings for Simple Retrieval Tasks,"Embeddings allow semantic search — they map text into vectors so the system can find content with similar meaning, even if the keywords don’t match. Keyword or metadata search, by contrast, looks for exact terms or simple filters. Many workloads (FAQ lookups, short product searches, rule-based routing) do not need semantic understanding and perform just as well with basic keyword logic. When teams",medium,published
CER-002089,azure,focus_database,azure-sql,Unnecessary Use of RA-GRS for Azure SQL Backup Storage,"Azure SQL databases often use the default backup configuration, which stores backups in RA-GRS storage to ensure geo-redundancy. While suitable for high-availability production systems, this level of resilience may be unnecessary for development, testing, or lower-impact workloads.Using RA-GRS without a business requirement results in avoidable costs. Downgrading to LRS or ZRS — where appropriate ",medium,published
CER-003284,gcp,focus_database,gcp-bigquery,Unoptimized Billing Model for BigQuery Dataset Storage,"Highly compressible datasets, such as those with repeated string fields, nested structures, or uniform rows, can benefit significantly from physical storage billing. Yet most datasets remain on logical storage by default, even when physical storage would reduce costs.This inefficiency is common for cold or infrequently updated datasets that are no longer optimized or regularly reviewed. Because st",medium,published
CER-007849,aws,focus_storage,aws-ebs,Unused EBS Volume Attached to a Stopped EC2 Instance,"This inefficiency occurs when an EC2 instance is stopped but still has one or more attached EBS volumes. Although the compute resource is not generating charges while stopped, the attached volumes continue to incur full storage and performance-related costs. These volumes are often overlooked in cost reviews, especially if the instance is temporarily paused or has been left in a stopped state long",medium,published
CER-004410,aws,focus_storage,aws-s3,Unused S3 Storage Lens Advanced,"S3 Storage Lens Advanced provides valuable insights into storage usage and trends, but it incurs a recurring cost. Organisations often enable it during an optimization initiative but fail to turn it off afterwards. When no active storage efficiency efforts are underway, these advanced metrics can become an unnecessary expense, especially at large scale across many buckets.Advanced metrics include ",medium,published
CER-003917,aws,focus_ai,aws-bedrock,Using High-Cost Bedrock Models for Low-Complexity Tasks,"Many Bedrock workloads involve low-complexity tasks such as tagging, classification, routing, entity extraction, keyword detection, document triage, or lightweight summarization. These tasks **do not require** the advanced reasoning or generative capabilities of higher-cost models such as Claude 3 Opus or comparable premium models. When organizations default to a high-end model across all applicat",medium,published
CER-009918,azure,focus_ai,azure-cognitive-services,Using High-Cost Models for Low-Complexity Tasks,"Some workloads — such as text classification, keyword extraction, intent detection, routing, or lightweight summarization — do not require the capabilities of the most advanced model families. When high-cost models are used for these simple tasks, organizations pay elevated token rates for work that could be handled effectively by more efficient, lower-cost models. This mismatch typically arises f",medium,published
CER-004421,gcp,focus_ai,gcp-vertex-ai,Using High-Cost Models for Low-Complexity Tasks,"Vertex AI workloads often include low-complexity tasks such as classification, routing, keyword extraction, metadata parsing, document triage, or summarization of short and simple text. These operations do **not** require the advanced multimodal reasoning or long-context capabilities of larger Gemini model tiers. When organizations default to a single high-end model (such as Gemini Ultra or Pro) a",medium,published
